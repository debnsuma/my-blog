<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Suman Debnath">
<meta name="dcterms.date" content="2025-11-30">
<meta name="description" content="In this blog, we’ll explore distributed training together, breaking down the core concepts and hands-on techniques for scaling deep learning models across multiple GPUs and machines using PyTorch and Ray.">

<title>From Single GPU to Clusters: A Practical Journey into Distributed Training with PyTorch and Ray – My Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/debnsuma"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/_sumand"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">From Single GPU to Clusters: A Practical Journey into Distributed Training with PyTorch and Ray</h1>
                  <div>
        <div class="description">
          In this blog, we’ll explore distributed training together, breaking down the core concepts and hands-on techniques for scaling deep learning models across multiple GPUs and machines using PyTorch and Ray.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">distributed-training</div>
                <div class="quarto-category">deep-learning</div>
                <div class="quarto-category">ray</div>
                <div class="quarto-category">pytorch</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Suman Debnath </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 30, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#deep-learning-training-basics" id="toc-deep-learning-training-basics" class="nav-link" data-scroll-target="#deep-learning-training-basics">Deep Learning Training Basics</a></li>
  <li><a href="#bottlenecks-in-single-gpu-training" id="toc-bottlenecks-in-single-gpu-training" class="nav-link" data-scroll-target="#bottlenecks-in-single-gpu-training">Bottlenecks in Single-GPU Training</a>
  <ul class="collapse">
  <li><a href="#static-memory" id="toc-static-memory" class="nav-link" data-scroll-target="#static-memory">Static Memory</a></li>
  <li><a href="#dynamic-memory" id="toc-dynamic-memory" class="nav-link" data-scroll-target="#dynamic-memory">Dynamic Memory</a></li>
  </ul></li>
  <li><a href="#batch-size-intuition" id="toc-batch-size-intuition" class="nav-link" data-scroll-target="#batch-size-intuition">Batch Size Intuition</a></li>
  <li><a href="#memory-usage-in-transformers" id="toc-memory-usage-in-transformers" class="nav-link" data-scroll-target="#memory-usage-in-transformers">Memory Usage in Transformers</a>
  <ul class="collapse">
  <li><a href="#solution-1-activation-recomputation" id="toc-solution-1-activation-recomputation" class="nav-link" data-scroll-target="#solution-1-activation-recomputation">Solution 1: Activation Recomputation</a></li>
  <li><a href="#solution-2-gradient-accumulation" id="toc-solution-2-gradient-accumulation" class="nav-link" data-scroll-target="#solution-2-gradient-accumulation">Solution 2: Gradient Accumulation</a></li>
  </ul></li>
  <li><a href="#scaling-with-multiple-gpus-data-parallelism-dp" id="toc-scaling-with-multiple-gpus-data-parallelism-dp" class="nav-link" data-scroll-target="#scaling-with-multiple-gpus-data-parallelism-dp">Scaling with Multiple GPUs: Data Parallelism (DP)</a>
  <ul class="collapse">
  <li><a href="#the-data-parallel-setup" id="toc-the-data-parallel-setup" class="nav-link" data-scroll-target="#the-data-parallel-setup">The Data Parallel Setup</a></li>
  <li><a href="#gradient-synchronization-the-all-reduce-primitive" id="toc-gradient-synchronization-the-all-reduce-primitive" class="nav-link" data-scroll-target="#gradient-synchronization-the-all-reduce-primitive">Gradient Synchronization: The All-Reduce Primitive</a></li>
  <li><a href="#overlapping-communication-and-computation" id="toc-overlapping-communication-and-computation" class="nav-link" data-scroll-target="#overlapping-communication-and-computation">Overlapping Communication and Computation</a></li>
  </ul></li>
  <li><a href="#the-limitations-of-simple-data-parallelism-dp" id="toc-the-limitations-of-simple-data-parallelism-dp" class="nav-link" data-scroll-target="#the-limitations-of-simple-data-parallelism-dp">The Limitations of Simple Data Parallelism (DP)</a></li>
  <li><a href="#zero-zero-redundancy-optimizer" id="toc-zero-zero-redundancy-optimizer" class="nav-link" data-scroll-target="#zero-zero-redundancy-optimizer">ZeRO: Zero Redundancy Optimizer</a>
  <ul class="collapse">
  <li><a href="#zero-1-sharding-optimizer-states" id="toc-zero-1-sharding-optimizer-states" class="nav-link" data-scroll-target="#zero-1-sharding-optimizer-states">ZeRO-1: Sharding <code>Optimizer States</code></a></li>
  <li><a href="#zero-2-sharding-gradients" id="toc-zero-2-sharding-gradients" class="nav-link" data-scroll-target="#zero-2-sharding-gradients">ZeRO-2: Sharding <code>Gradients</code></a></li>
  <li><a href="#zero-3-sharding-parameters" id="toc-zero-3-sharding-parameters" class="nav-link" data-scroll-target="#zero-3-sharding-parameters">ZeRO-3: Sharding <code>Parameters</code></a></li>
  </ul></li>
  <li><a href="#introduction-to-ray---unified-ai-compute-engine" id="toc-introduction-to-ray---unified-ai-compute-engine" class="nav-link" data-scroll-target="#introduction-to-ray---unified-ai-compute-engine">Introduction to Ray - <code>Unified AI Compute Engine</code></a>
  <ul class="collapse">
  <li><a href="#ray-core-primitives" id="toc-ray-core-primitives" class="nav-link" data-scroll-target="#ray-core-primitives">Ray Core Primitives</a></li>
  <li><a href="#an-example-for-stateless-tasks-tasks" id="toc-an-example-for-stateless-tasks-tasks" class="nav-link" data-scroll-target="#an-example-for-stateless-tasks-tasks">An example: For <code>Stateless</code> Tasks (Tasks)</a></li>
  <li><a href="#going-further-for-stateful-tasks-actors" id="toc-going-further-for-stateful-tasks-actors" class="nav-link" data-scroll-target="#going-further-for-stateful-tasks-actors">Going Further: For <code>Stateful</code> Tasks (Actors)</a></li>
  <li><a href="#ray-for-different-ai-workloads" id="toc-ray-for-different-ai-workloads" class="nav-link" data-scroll-target="#ray-for-different-ai-workloads">Ray for Different AI Workloads</a></li>
  </ul></li>
  <li><a href="#distributed-training-with-ray-train-and-pytorch" id="toc-distributed-training-with-ray-train-and-pytorch" class="nav-link" data-scroll-target="#distributed-training-with-ray-train-and-pytorch">Distributed Training with Ray Train and PyTorch</a>
  <ul class="collapse">
  <li><a href="#single-gpu-pytorch-training-on-cifar-10" id="toc-single-gpu-pytorch-training-on-cifar-10" class="nav-link" data-scroll-target="#single-gpu-pytorch-training-on-cifar-10">Single-GPU PyTorch Training on CIFAR-10</a>
  <ul class="collapse">
  <li><a href="#dataloader-function" id="toc-dataloader-function" class="nav-link" data-scroll-target="#dataloader-function">DataLoader Function</a></li>
  <li><a href="#training-function" id="toc-training-function" class="nav-link" data-scroll-target="#training-function">Training Function</a></li>
  <li><a href="#training-the-model" id="toc-training-the-model" class="nav-link" data-scroll-target="#training-the-model">Training the Model</a></li>
  </ul></li>
  <li><a href="#distributed-training-with-ray-train" id="toc-distributed-training-with-ray-train" class="nav-link" data-scroll-target="#distributed-training-with-ray-train">Distributed Training with Ray Train</a>
  <ul class="collapse">
  <li><a href="#ray-train-architecture" id="toc-ray-train-architecture" class="nav-link" data-scroll-target="#ray-train-architecture">Ray Train Architecture</a></li>
  <li><a href="#ray-data-and-ray-train-integration" id="toc-ray-data-and-ray-train-integration" class="nav-link" data-scroll-target="#ray-data-and-ray-train-integration">Ray Data and Ray Train Integration</a></li>
  </ul></li>
  <li><a href="#setup-the-environment" id="toc-setup-the-environment" class="nav-link" data-scroll-target="#setup-the-environment">Setup the Environment</a></li>
  <li><a href="#distributed-training-with-ray-train-and-pytorch-fsdp" id="toc-distributed-training-with-ray-train-and-pytorch-fsdp" class="nav-link" data-scroll-target="#distributed-training-with-ray-train-and-pytorch-fsdp">Distributed Training with Ray Train and PyTorch FSDP</a>
  <ul class="collapse">
  <li><a href="#specify-cluster-scaling" id="toc-specify-cluster-scaling" class="nav-link" data-scroll-target="#specify-cluster-scaling">1. Specify Cluster Scaling</a></li>
  <li><a href="#data-preparation-pytorch-dataloaders" id="toc-data-preparation-pytorch-dataloaders" class="nav-link" data-scroll-target="#data-preparation-pytorch-dataloaders">2. Data Preparation: PyTorch DataLoaders</a></li>
  <li><a href="#define-the-training-function-1" id="toc-define-the-training-function-1" class="nav-link" data-scroll-target="#define-the-training-function-1">3. Define the Training Function</a></li>
  <li><a href="#configure-run-checkpointing-and-storage" id="toc-configure-run-checkpointing-and-storage" class="nav-link" data-scroll-target="#configure-run-checkpointing-and-storage">4. Configure Run Checkpointing and Storage</a></li>
  <li><a href="#launch-training-with-torchtrainer" id="toc-launch-training-with-torchtrainer" class="nav-link" data-scroll-target="#launch-training-with-torchtrainer">5. Launch Training with TorchTrainer</a></li>
  <li><a href="#load-and-use-checkpoints" id="toc-load-and-use-checkpoints" class="nav-link" data-scroll-target="#load-and-use-checkpoints">6. Load and Use Checkpoints</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#references-further-resources" id="toc-references-further-resources" class="nav-link" data-scroll-target="#references-further-resources">References &amp; Further Resources</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Deep learning models are growing larger and more complex by the day and so are the challenges in training them. I’m actually quite new to distributed training myself, currently trying to figure out how to scale training across multiple GPUs and even multiple machines using different forms of parallelism.</p>
<p>What I’ve quickly discovered is that the bigger challenge isn’t the training algorithm itself, but understanding how distributed systems work and how to manage resources (GPUs and CPUs) efficiently!</p>
<p align="center">
<img src="assets/model_params.png" alt="Model Parameters vs Training Time" width="100%">
</p>
<p>As models get larger, the time to train explodes, sometimes taking days, weeks, or even months just for a single epoch on one GPU.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 30%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th style="text-align: center;">Parameters<br>(Millions)</th>
<th style="text-align: center;">Training Time on A100<br>(GPU Hours)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>ResNet-50</strong></td>
<td style="text-align: center;">26</td>
<td style="text-align: center;">31</td>
</tr>
<tr class="even">
<td><strong>ResNet-101</strong></td>
<td style="text-align: center;">45</td>
<td style="text-align: center;">44</td>
</tr>
<tr class="odd">
<td><strong>BERT-Base</strong></td>
<td style="text-align: center;">108</td>
<td style="text-align: center;">84</td>
</tr>
<tr class="even">
<td><strong>Turing-NLG 17B</strong></td>
<td style="text-align: center;">17,000</td>
<td style="text-align: center;">TBA</td>
</tr>
<tr class="odd">
<td><strong>GPT-3 175B</strong></td>
<td style="text-align: center;">175,000</td>
<td style="text-align: center;">3,100,000</td>
</tr>
</tbody>
</table>
<p>Looking at this table, you can see a dramatic surge in both parameter counts and training times:</p>
<ul>
<li><strong>ResNet-50</strong> and <strong>ResNet-101</strong> are manageable with a single GPU, but BERT-Base is already pushing the limits.</li>
<li><strong>Turing-NLG 17B</strong> and especially <strong>GPT-3 175B</strong> enter a whole new league, demanding immense computing power and time.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If we tried to train GPT-3 on a single GPU, it would take roughly <strong>355 years</strong> to finish. Distributed training is not just useful, it’s absolutely essential as model sizes and training time requirements soar</p>
</div>
</div>
<p>But why does this happen?</p>
<ul>
<li>Model sizes and GPU demand are exploding.</li>
<li>Training these models can require millions of GPU hours.</li>
</ul>
<p>Take the <code>LLaMA</code> family of models as an example. The graph below illustrates that as you increase model size (shown by circle diameter), you get better performance, but you’ll need even more training time. Look at the y-axis: we’re talking <em>millions</em> of GPU hours! Training any of these giants on a single GPU is not just slow, it’s practically impossible.</p>
<p align="center">
<img src="assets/model-size-vs-performance.png" alt="Model Size vs Performance" width="70%">
</p>
<p>In this blog post, we’ll explore distributed training from the ground up, learning how to scale deep learning to multiple GPUs and machines with various parallelism techniques. We’ll see how to implement these strategies from scratch using <code>PyTorch</code>, then level up by using <code>Ray</code> for scalable training.</p>
<p>As I mentioned, I’m still in the first epoch of my distributed training journey! And as I learn more shall keep updating this writeup.</p>
<p>Before I dive in, I’d like to thank some of the brilliant minds, mentors, and friends who’ve helped me along the way: <strong>Prof.&nbsp;Tanmoy Chakraborty</strong>, <strong>Dr.&nbsp;Yatin Nandwani</strong>, <strong>Prof.&nbsp;Song Han</strong>, my mentor <strong>Rohan Shravan</strong> (for his exceptional teaching and guidance over the years), and friends/colleagues like <strong>Dipankar Ranjan Baisya</strong>, <strong>Chris Fregly</strong>, <strong>Zachary Mueller</strong>, <strong>Ram Mohan</strong>, <strong>Debanjan Saha</strong>, and <strong>Siddhant Gupta</strong>.</p>
<p>Most of the content here is inspired by their work, lectures, and advice. All references and resources are at the end of this post.</p>
</section>
<section id="deep-learning-training-basics" class="level2">
<h2 class="anchored" data-anchor-id="deep-learning-training-basics">Deep Learning Training Basics</h2>
<p>Before diving into scaling, let’s quickly review the standard model training loop, such as a simple <strong>Multi-Layer Perceptron (MLP)</strong>:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" href="">Pseudo Code for the Training Loop</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>  model <span class="op">=</span> MLP().to(device)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>  optimizer <span class="op">=</span> Adam(model.parameters())</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>  criterion <span class="op">=</span> CrossEntropyLoss()</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>  data_loader <span class="op">=</span> DataLoader(dataset)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>  <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span>      model.train()  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="dv">8</span>      <span class="cf">for</span> inputs, targets <span class="kw">in</span> data_loader:</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="dv">9</span>          <span class="co"># 1. Move batch to GPU</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span>         inputs, targets <span class="op">=</span> inputs.to(device), targets.to(device)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span>         </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="dv">12</span>         <span class="co"># 2. Clear gradients</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="dv">13</span>         optimizer.zero_grad()</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="dv">14</span>         </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="dv">15</span>         <span class="co"># 3. Forward pass</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="dv">16</span>         outputs <span class="op">=</span> model(inputs)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="dv">17</span>         loss <span class="op">=</span> criterion(outputs, targets)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="dv">18</span>         </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="dv">19</span>         <span class="co"># 4. Backpropagation</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="dv">20</span>         loss.backward()</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="dv">21</span>         </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="dv">22</span>         <span class="co"># 5. Optimization</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="dv">23</span>         optimizer.step()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p>What’s happening in each epoch of this training loop?</p>
<ol type="1">
<li>We iterate over the data in mini-batches (<code>line 6-8</code>).</li>
<li>Move each batch to the GPU (<code>line 9-10</code>).</li>
<li>Zero out the gradients (<code>line 12-13</code>).</li>
<li>Run the forward pass and compute loss (<code>line 15-17</code>).</li>
<li>Perform backpropagation to compute gradients (<code>line 18-19</code>).</li>
<li>Update the model with the optimizer (<code>line 20-21</code>).</li>
</ol>
<p align="center">
<img src="assets/single-gpu.png" alt="Single GPU Training Loop" width="70%">
</p>
<p>This pattern is the core of most deep learning training loop (in fact, it is the core of any machine learning training routine).</p>
</section>
<section id="bottlenecks-in-single-gpu-training" class="level2">
<h2 class="anchored" data-anchor-id="bottlenecks-in-single-gpu-training">Bottlenecks in Single-GPU Training</h2>
<p>When training deep learning models on a single GPU, there are four main things that eat up high-bandwidth memory (HBM):</p>
<ol type="1">
<li><strong>Model Parameters</strong> (<span class="math inline">\(\Phi\)</span>):<br>
These are the weights your model is learning.</li>
<li><strong>Parameter Gradients</strong> (<span class="math inline">\(\nabla \Phi\)</span>):<br>
The gradients calculated during backpropagation, which are used to update parameters.</li>
<li><strong>Optimizer States</strong> (<span class="math inline">\(\Phi_{\text{optim}}\)</span>):<br>
Extra variables required by the optimizer, such as momentum and variance in <code>Adam</code>.</li>
<li><strong>Activations</strong> (<span class="math inline">\(\mathcal{M}_{\text{act}}\)</span>):<br>
The intermediate outputs of each layer, which are necessary for gradient computation during backprop.</li>
</ol>
<p>The first three (<strong>parameters</strong>, <strong>gradients</strong>, and <strong>optimizer states</strong>) are <strong>static</strong>, they make up the fixed memory footprint determined by the model’s architecture.</p>
<p>The activations are <strong>dynamic</strong>, depending on your batch and sequence length, and often become the main bottleneck for large-scale training.</p>
<section id="static-memory" class="level3">
<h3 class="anchored" data-anchor-id="static-memory">Static Memory</h3>
<p>If you revisit the training loop, you’ll notice that up until <code>optimizer.step()</code>, everything must be retained in memory. After that, you can discard activations and gradients, but the model parameters and optimizer states stick around.</p>
<p>If <span class="math inline">\(\Psi\)</span> is the total number of model parameters, the static memory required (<span class="math inline">\(\mathcal{M}_{static}\)</span>) using the Adam optimizer is a crisp: <strong><span class="math inline">\(16\Psi\)</span> bytes</strong>.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 18%">
<col style="width: 20%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th>Precision</th>
<th style="text-align: center;">Size (<span class="math inline">\(\Psi\)</span> Bytes)</th>
<th style="text-align: left;">Details</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Model Parameters</td>
<td>BF32 (4 bytes)</td>
<td style="text-align: center;"><span class="math inline">\(4\Psi\)</span></td>
<td style="text-align: left;">Used for fwd/back passes</td>
</tr>
<tr class="even">
<td>Parameter Gradients</td>
<td>BF32 (4 bytes)</td>
<td style="text-align: center;"><span class="math inline">\(4\Psi\)</span></td>
<td style="text-align: left;">For backpropagation</td>
</tr>
<tr class="odd">
<td>Optimizer States (Adam)</td>
<td>FP32 (4+4 bytes)</td>
<td style="text-align: center;"><span class="math inline">\(8\Psi\)</span></td>
<td style="text-align: left;">1st and 2nd moment estimates</td>
</tr>
<tr class="even">
<td><strong>Total Static Memory</strong></td>
<td></td>
<td style="text-align: center;"><strong><span class="math inline">\(16\Psi\)</span></strong></td>
<td style="text-align: left;"><strong>Absolute minimum for static storage</strong></td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-note callout-titled" title="Why Adam Optimizer Uses $4+4$ Bytes per Parameter">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Why Adam Optimizer Uses <span class="math inline">\(4+4\)</span> Bytes per Parameter
</div>
</div>
<div class="callout-body-container callout-body">
<p>Adam maintains two additional FP32 (4-byte) tensors per parameter: the <strong>first moment</strong> (mean of gradients, <span class="math inline">\(m\)</span>) and the <strong>second moment</strong> (uncentered variance, <span class="math inline">\(v\)</span>). Thus, for each parameter, Adam stores <span class="math inline">\(4\)</span> bytes for <span class="math inline">\(m\)</span> and <span class="math inline">\(4\)</span> bytes for <span class="math inline">\(v\)</span>, totaling <span class="math inline">\(8\Psi\)</span> bytes.</p>
</div>
</div>
<p>When optimizing large models, memory management becomes an art. Modern LLM training uses <strong>mixed precision</strong>, typically BF16 (2 bytes) for fast compute, but still maintaining an FP32 (4 bytes) copy for weights and optimizer states to preserve accuracy.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Mixed Precision Training">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Mixed Precision Training
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Mixed Precision Training</strong> accelerates deep learning and reduces memory usage by combining 16-bit (BF16/FP16) and 32-bit (FP32) floating-point operations.</p>
<ul>
<li><em>How?</em> Forward/backward passes run with low-precision types (BF16), while an FP32 <code>master</code> copy is kept for stability.</li>
<li><em>Why care?</em> Allows larger models/batches to fit in memory and speeds up training. Mixed precision is now standard for large-scale model training.</li>
</ul>
</div>
</div>
<p>With mixed precision, the memory usage looks like this:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 17%">
<col style="width: 20%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th>Precision</th>
<th style="text-align: center;">Size (<span class="math inline">\(\Psi\)</span> Bytes)</th>
<th style="text-align: left;">Details</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Model Parameters</td>
<td>BF16 (2 bytes)</td>
<td style="text-align: center;"><span class="math inline">\(2\Psi\)</span></td>
<td style="text-align: left;">For forward/backward passes</td>
</tr>
<tr class="even">
<td>Parameter Gradients</td>
<td>BF16 (2 bytes)</td>
<td style="text-align: center;"><span class="math inline">\(2\Psi\)</span></td>
<td style="text-align: left;">Backpropagation</td>
</tr>
<tr class="odd">
<td>Master Weights</td>
<td>FP32 (4 bytes)</td>
<td style="text-align: center;"><span class="math inline">\(4\Psi\)</span></td>
<td style="text-align: left;">For weight updates</td>
</tr>
<tr class="even">
<td>Optimizer States (Adam)</td>
<td>FP32 (4+4 bytes)</td>
<td style="text-align: center;"><span class="math inline">\(8\Psi\)</span></td>
<td style="text-align: left;">1st/2nd moment estimates</td>
</tr>
<tr class="odd">
<td><strong>Total Static Memory</strong></td>
<td></td>
<td style="text-align: center;"><strong><span class="math inline">\(16\Psi\)</span></strong></td>
<td style="text-align: left;"><strong>Unchanged overall</strong></td>
</tr>
</tbody>
</table>
<p>You might notice that the total static memory remains <strong><span class="math inline">\(16\Psi\)</span></strong> bytes. So what is the advantage of mixed precision training?</p>
<ul>
<li><strong>Faster Training:</strong> Using BF16 reduces computation time and memory bandwidth.</li>
<li><strong>Activations Use Half the Memory:</strong> Activations (stored in BF16) become much lighter.</li>
</ul>
<p>Even though the static footprint isn’t reduced, training can run <em>faster</em>, and we can fit larger dynamic activations, squeezing the most out of every GPU.</p>
<p>But here’s the hard truth: a <strong>70B parameter model</strong> eats up around <span class="math inline">\(70\text{B} \times 16\text{ bytes} = 1120\text{ GB}\)</span> of static memory, which is far beyond a single A100 GPU’s 80GB. And that’s before counting activations!</p>
</section>
<section id="dynamic-memory" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-memory">Dynamic Memory</h3>
<p>Dynamic memory, mainly activations, is completely input-dependent and usually the cause of memory headaches.</p>
<ul>
<li><p><strong>Activations:</strong> The output of each layer. They must be stored until the <strong>backward pass</strong> to compute the gradients.</p>
<ul>
<li>For a linear layer <span class="math inline">\(y=Wx\)</span>, the gradient for <span class="math inline">\(W\)</span> is calculated as: <span class="math display">\[\frac{\partial L}{\partial W} = \frac{\partial L}{\partial y} \cdot x^T\]</span></li>
<li>This requires saving the layer’s input, <span class="math inline">\(x\)</span> (the activation from the previous layer).</li>
</ul></li>
<li><p><strong>Activation Memory Equation:</strong> The total memory required for activations (<span class="math inline">\(m_{act}\)</span>) in mixed precision can be estimated by the following equation: <span class="math display">\[\mathcal{M}_{\text{act}} = L \cdot \text{seq} \cdot \text{bs} \cdot h \cdot \left(34 + \frac{5 \cdot n_{heads} \cdot \text{seq}}{\text{h}}\right)\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(L\)</span>: Number of layers</li>
<li><span class="math inline">\(\text{seq}\)</span>: Sequence length</li>
<li><span class="math inline">\(\text{bs}\)</span>: Batch size (number of samples)</li>
<li><span class="math inline">\(h\)</span>: Hidden dimension of the model</li>
<li><span class="math inline">\(n_{heads}\)</span>: Number of attention heads</li>
</ul></li>
</ul>
<p align="center">
<img src="assets/activations.png" alt="Activation Count" width="70%">
</p>
<p>As we can see, activation memory usage is <strong>not static</strong> for a given model, it:</p>
<ul>
<li>Grows <code>linearly</code> with batch size (<span class="math inline">\(bs\)</span>)</li>
<li>Grows <code>quadratically</code> with sequence length (<span class="math inline">\(seq\)</span>)</li>
</ul>
<p>This quadratic growth (thanks, attention matrix!) is why activation memory swells out of control when you increase batch size or sequence length.</p>
</section>
</section>
<section id="batch-size-intuition" class="level2">
<h2 class="anchored" data-anchor-id="batch-size-intuition">Batch Size Intuition</h2>
<p>As you might guess, longer sequences mean more activations, which means more memory. In fact, memory for even a single long sequence can exceed 50GB! Training large models? It’s a real constraint.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Global Batch Size">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Global Batch Size
</div>
</div>
<div class="callout-body-container callout-body">
<p>In LLM pre-training, batch size typically means <strong>number of tokens</strong>, not sequences. Token batch size is simply <strong>sequence length × micro-batch size</strong>.</p>
</div>
</div>
<p>Real-world pre-training uses massive global batch sizes, often <strong>millions of tokens</strong>. In practice, training begins with smaller batches (for noisy, fast progress), then scales up batch size for stability and accuracy as you approach convergence.</p>
<ul>
<li><strong>Small batches:</strong> Early phase, high loss, helps the model learn quickly.</li>
<li><strong>Big batches:</strong> Later phase, less noise, more stable gradients.</li>
</ul>
<p align="center">
<img src="assets/batch-size.png" alt="Batch Size Intuition" width="100%">
</p>
</section>
<section id="memory-usage-in-transformers" class="level2">
<h2 class="anchored" data-anchor-id="memory-usage-in-transformers">Memory Usage in Transformers</h2>
<p>To appreciate the scale of this, let’s take a look at the memory usage in <code>Llama 3.1</code> models (<code>8B</code>, <code>13B</code>, <code>70B</code>).</p>
<p align="center">
<img src="assets/llama-3-1.png" alt="Batch Size Intuition" width="100%">
</p>
<p>From this graph, we can clearly see that for short sequences (or small batch sizes), memory usage for activations is almost negligible, but from around 4K-16K tokens they start to take up a significant amount of memory (this is because of the quadratic scaling with the sequence length, which we discussed earlier), while usage for parameters, gradients, and optimizer states is roughly independent of the sequence length and batch size.</p>
<p>How can we solve this problem of <code>activation explosion</code>? Can we somehow avoide storing all those activations ?</p>
<section id="solution-1-activation-recomputation" class="level3">
<h3 class="anchored" data-anchor-id="solution-1-activation-recomputation">Solution 1: Activation Recomputation</h3>
<p>Why do we <strong>store all these activations</strong>? We need them to compute parameter gradients during backward pass. What if we could avoid keeping every activation in memory?</p>
<p>This is what <strong>gradient checkpointing</strong> does, which is also known as <strong>activation recomputation</strong>. With this technique, we keep only a few activations in memory during the forward pass and recompute the missing ones <code>on-the-fly</code> during backward. We save memory, but at the cost of more compute!</p>
<p>Normally, we’d store every hidden state between learnable operations (like feedforward layers, layer norm, etc.) to use them during the backward pass. With activation recomputation, we only store activations at specific checkpoints and recalculate everything else during backpropagation. This helps us manage memory while training large models.</p>
<p align="center">
<img src="assets/gradient-accumulation-1.png" alt="Gradient Accumulation" width="70%">
</p>
<p>But there is no free lunch, although memory is saved, we pay with extra computation as activations are re-created during backward. There are a few ways to do activation checkpointing, and each involves different memory and compute tradeoffs.</p>
<p>The most aggressive approach is called <strong>Full Activation Checkpointing</strong>, where you only store activations at the end of each layer (instead of storing every intermediate activation). This method is great for memory since you’re keeping so little, but it’s the most compute-heavy, often increasing computation time by 30–40% because you have to <code>recompute</code> almost everything during backpropagation.</p>
<p>But do we really need to treat every part of the model the same? By profiling, we find that the main memory culprit is the activations from the <strong>Multi-Headed Attention (MHA)</strong> layers, since they scale <code>quadratically</code> with sequence length.</p>
<p>This leads to a more balanced strategy: <strong>Selective Checkpointing</strong>. Here, we only skip storing activations for the heavy MHA layers and still store them for the lighter MLP layers. The payoff is impressive: up to 70% memory savings for only about 2.7% extra computation.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Activation Checkpointing on Llama 3.1 8B model">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Activation Checkpointing on Llama 3.1 8B model
</div>
</div>
<div class="callout-body-container callout-body">
<p>As you can see the graph bellow, on an <strong>8B parameter model</strong> with a <strong>batch size of 1</strong> and <strong>sequence length 4096</strong>, activation memory without any checkpointing can hit 97 GB, which is enough to break most GPUs. With <code>selective activation checkpointing</code>, that drops to 17 GB. And with <code>full checkpointing</code>, at the extreme, memory usage can go down to just 1 GB!</p>
</div>
</div>
<p align="center">
<img src="assets/llama-checkp.png" alt="Gradient Accumulation" width="100%">
</p>
<p>Now that we’ve learned about recomputation, we can tame the activation memory usage we saw in the previous graphs!</p>
<p>However, activations still have a linear dependence on the batch size, so as we move to larger batch sizes this might become an issue again. So, what can we do to increase the batch size ?</p>
<p>And to tackle this we have the next trick in our box, <strong>gradient accumulation</strong>, which we will discuss next.</p>
</section>
<section id="solution-2-gradient-accumulation" class="level3">
<h3 class="anchored" data-anchor-id="solution-2-gradient-accumulation">Solution 2: Gradient Accumulation</h3>
<p><strong>Gradient Accumulation</strong> is a technique that allows us to accumulate gradients over <code>multiple micro-batches</code> before performing a single global optimization step. This is particularly useful when we have a large batch size and we want to avoid running out of memory.</p>
<p>The general idea is to split the batch into smaller micro-batches (let’s say 3) and process them one by one. We compute the gradients for each micro-batch and accumulate them (we <strong>do not do</strong> <code>optimizer.step()</code> after each micro-batch). And after processing all the micro-batches, <strong>we perform a single global optimization step</strong>.</p>
<p align="center">
<img src="assets/grad-acc.png" alt="Gradient Accumulation" width="100%">
</p>
<p>Let’s take an example of a simple linear regression model, predicting the <strong>score of a student on a test</strong> based on two factors:</p>
<ul>
<li>the <code>number of hours studied</code> (<span class="math inline">\(x_1\)</span>) and</li>
<li>the <code>number of hours slept the night before</code> (<span class="math inline">\(x_2\)</span>).</li>
</ul>
<p>We assume a simple linear relationship between these inputs and the output score: <span class="math display">\[
\text{score}_{pred} = x_1 w_1 + x_2 w_2 + b
\]</span> Our aim is to use stochastic gradient descent to determine the best values for <span class="math inline">\(w_1\)</span>, <span class="math inline">\(w_2\)</span>, and <span class="math inline">\(b\)</span> such that the mean squared error (MSE) between the actual score (<span class="math inline">\(\text{score}_{target}\)</span>) and the predicted score (<span class="math inline">\(\text{score}_{pred}\)</span>) is minimized: <span class="math display">\[
\underset{w_1, w_2, b}{\mathrm{argmin}} \; (\text{score}_{pred} - \text{score}_{target})^2
\]</span> Without gradient accumulation, we would update the parameters after each batch of student’s data.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true" href="">Without Gradient Accumulation</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>  <span class="kw">def</span> train_no_accumulate(params: ModelParameters, </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>                         num_epochs: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span>, </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>                         learning_rate: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-3</span>):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>      <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, num_epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>          <span class="cf">for</span> (x1, x2), y_target <span class="kw">in</span> training_data:</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span>              <span class="co"># Calculate the output of the model</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="dv">8</span>              z1 <span class="op">=</span> x1 <span class="op">*</span> params.w1</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="dv">9</span>              z2 <span class="op">=</span> x2 <span class="op">*</span> params.w2</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span>             y_pred <span class="op">=</span> z1 <span class="op">+</span> z2 <span class="op">+</span> params.b</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span>             loss <span class="op">=</span> (y_pred <span class="op">-</span> y_target) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="dv">12</span> </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="dv">13</span>             <span class="co"># Calculate the gradients of the loss w.r.t. the parameters</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="dv">14</span>             loss.backward()</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="dv">15</span> </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="dv">16</span>             <span class="co"># Update the parameters (at each iteration)</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="dv">17</span>             <span class="cf">with</span> torch.no_grad():</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="dv">18</span>                 <span class="co"># Equivalent to calling optimizer.step()</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="dv">19</span>                 params.w1 <span class="op">-=</span> learning_rate <span class="op">*</span> params.w1.grad</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="dv">20</span>                 params.w2 <span class="op">-=</span> learning_rate <span class="op">*</span> params.w2.grad</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="dv">21</span>                 params.b  <span class="op">-=</span> learning_rate <span class="op">*</span> params.b.grad</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="dv">22</span> </span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="dv">23</span>                 <span class="co"># Reset the gradients to zero</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="dv">24</span>                 <span class="co"># Equivalent to calling optimizer.zero_grad()</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="dv">25</span>                 params.w1.grad.zero_()</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="dv">26</span>                 params.w2.grad.zero_()</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="dv">27</span>                 params.b.grad.zero_()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p>With <strong>gradient accumulation</strong>, instead of updating the parameters after each batch of data, we accumulate gradients across several micro-batches (<code>micro_batch_size = 3</code>) and then update all at once.</p>
<p>This allows us to train with larger effective batch sizes even if memory is limited.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true" href="">With Gradient Accumulation</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>  <span class="kw">def</span> train_accumulate(params: ModelParameters, </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>                       num_epochs: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span>, </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>                       learning_rate: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-3</span>, </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>                       micro_batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">3</span>):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>      <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, num_epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span>          <span class="cf">for</span> index, ((x1, x2), y_target) <span class="kw">in</span> <span class="bu">enumerate</span>(training_data):</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="dv">8</span>  </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="dv">9</span>              <span class="co"># Calculate the output of the model</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span>             z1 <span class="op">=</span> x1 <span class="op">*</span> params.w1</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span>             z2 <span class="op">=</span> x2 <span class="op">*</span> params.w2</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="dv">12</span>             y_pred <span class="op">=</span> z1 <span class="op">+</span> z2 <span class="op">+</span> params.b</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="dv">13</span>             loss <span class="op">=</span> (y_pred <span class="op">-</span> y_target) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="dv">14</span> </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="dv">15</span>             <span class="co"># Accumulate gradients</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="dv">16</span>             loss.backward()</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="dv">17</span> </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="dv">18</span>             <span class="co"># If we have processed 3 micro-batches OR reached the end of the dataset</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="dv">19</span>             <span class="cf">if</span> (index <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> micro_batch_size <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> index <span class="op">==</span> <span class="bu">len</span>(training_data) <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="dv">20</span>                 <span class="cf">with</span> torch.no_grad():</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="dv">21</span>                     <span class="co"># Equivalent to optimizer.step()</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="dv">22</span>                     params.w1 <span class="op">-=</span> learning_rate <span class="op">*</span> params.w1.grad</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="dv">23</span>                     params.w2 <span class="op">-=</span> learning_rate <span class="op">*</span> params.w2.grad</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="dv">24</span>                     params.b  <span class="op">-=</span> learning_rate <span class="op">*</span> params.b.grad</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="dv">25</span> </span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="dv">26</span>                     <span class="co"># Reset the gradients = optimizer.zero_grad()</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="dv">27</span>                     params.w1.grad.zero_()</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="dv">28</span>                     params.w2.grad.zero_()</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="dv">29</span>                     params.b.grad.zero_()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p><strong>Gradient accumulation</strong> allows us to reduce activation memory, which grows linearly with batch size, by processing smaller micro-batches sequentially. This reduces stored activations and gradients since only one micro-batch’s worth of activations needs to be kept in memory at a time, which helps reduce the overall activation memory footprint.</p>
<p>Again, there’s a trade-off: gradient accumulation increases computation (more forward/backward passes before each optimizer step), so it can slow down training. But it enables much larger effective batch sizes on limited hardware.</p>
<p>So far, we’ve seen how techniques like <code>gradient checkpointing</code> and <code>gradient accumulation</code> help deal with the memory blowup issue caused by <code>activations</code>: the <strong>dynamic memory usage</strong>.</p>
<p>Both allow us to fit larger models or batches on a <strong>single GPU</strong>, but mostly by working sequentially and slowing down training. However, these don’t address the <strong>static memory</strong> required for parameters, gradients, and optimizer states, nor do they fully utilize available hardware (assume we have more than one GPU).</p>
<p>To tackle this, we can scale training across multiple GPUs using <strong>Data Parallelism</strong>. By splitting micro-batches and processing them simultaneously on several GPUs, we address both memory and compute bottlenecks.</p>
</section>
</section>
<section id="scaling-with-multiple-gpus-data-parallelism-dp" class="level2">
<h2 class="anchored" data-anchor-id="scaling-with-multiple-gpus-data-parallelism-dp">Scaling with Multiple GPUs: Data Parallelism (DP)</h2>
<p>Recall that in Gradient Accumulation, we were processing <strong>micro-batches (MBS)</strong> sequentially. Since these micro-batches are <strong>independent of each other</strong>, we can process them <strong>parallelly on different GPUs</strong>.</p>
<p>Something like this below: if you look carefully, now we are processing the <code>micro-batches</code> in <strong>parallel</strong> on different GPUs, whereas in Gradient Accumulation we were processing the <code>micro-batches</code> <strong>sequentially</strong> on a single GPU. This is what we do in Data Parallelism (DP).</p>
<p align="center">
<img src="assets/dp.png" alt="Data Parallelism" width="100%">
</p>
<section id="the-data-parallel-setup" class="level3">
<h3 class="anchored" data-anchor-id="the-data-parallel-setup">The Data Parallel Setup</h3>
<p>In a Data Parallel setup, we distribute the data across multiple GPUs, while maintaining a full, redundant replica of the <code>model parameters</code>, <code>gradients</code>, and <code>optimizer states</code> on each GPU.</p>
<ol type="1">
<li><strong>Replication:</strong> We maintain a full, redundant <strong>replica</strong> of the model parameters (<span class="math inline">\(\Phi\)</span>), gradients (<span class="math inline">\(\nabla \Phi\)</span>), and optimizer states (<span class="math inline">\(\Phi_{\text{optim}}\)</span>) on <strong>each GPU</strong>.</li>
</ol>
<p align="center">
<img src="assets/dp_1.png" alt="Data Parallel Setup" width="100%">
</p>
<ol start="2" type="1">
<li><strong>Parallel Processing:</strong> Each GPU processes a unique micro-batch simultaneously. This involves <strong>same operations, different data</strong>, which is also known as <code>SIMD</code> (Single Instruction Multiple Data).</li>
</ol>
<p align="center">
<img src="assets/dp_2.png" alt="Data Parallel Setup" width="100%">
</p>
<ol start="3" type="1">
<li><strong>Local Computation:</strong> Each GPU performs its forward pass and backward pass locally and independently, resulting in a local gradient (<span class="math inline">\(\nabla \Phi_i\)</span>).</li>
</ol>
<p align="center">
<img src="assets/dp_3.png" alt="Data Parallel Setup" width="100%">
</p>
<p>If you look carefully, we <strong>can</strong> perform the forward pass and the backward pass in <strong>parallel</strong> on different GPUs. But we <strong>cannot</strong> perform the optimizer step and update the parameters independently on different GPUs. If we do that, we will end up training <code>N</code> different models on <code>N</code> different GPUs which is not what we want.</p>
<p>So, after the backward pass, we need to synchronize the gradients across the GPUs. This is accomplished using the <strong>All-Reduce</strong> primitive.</p>
</section>
<section id="gradient-synchronization-the-all-reduce-primitive" class="level3">
<h3 class="anchored" data-anchor-id="gradient-synchronization-the-all-reduce-primitive">Gradient Synchronization: The All-Reduce Primitive</h3>
<p>Before we dive into the <strong>All-Reduce</strong> operation, it’s important to note that NVIDIA provides a rich set of <strong>communication primitives</strong> as part of its distributed training ecosystem such as <strong>NCCL</strong> (NVIDIA’s collective communication library). These primitives simplify and accelerate multi-GPU (and multi-node) communication, enabling efficient synchronization and sharding operations required for large-scale training.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Communication Primitives in Distributed Training">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Communication Primitives in Distributed Training
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>All-Reduce</strong> is just one such primitive, used specifically for synchronizing gradients across GPUs at the end of each backward pass in standard Data Parallel training. However, there are several other primitives (like <strong>All-Gather</strong>, <strong>Reduce-Scatter</strong>, <strong>Broadcast</strong>, etc.) designed for different patterns of communication and parallelism.</p>
<p>We will discuss these additional primitives as we encounter them while exploring more advanced parallelization techniques (e.g., ZeRO, model sharding, and tensor parallelism) later in the series.</p>
</div>
</div>
<p>For now, let’s look at <strong>All-Reduce</strong> in detail, since this is exactly what we need for synchronizing the gradients during Data Parallel training.</p>
<p>Since each GPU computes a gradient based only on its local micro-batch, we must <strong>add them to get the global gradient</strong> before performing the optimization step. The required communication operation is the <strong>All-Reduce</strong> primitive:</p>
<ul>
<li><strong>Input:</strong> Different tensors (the local gradients <span class="math inline">\(\nabla \Phi_1, \nabla \Phi_2, \dots\)</span>) on each GPU.</li>
<li><strong>Operation:</strong> A reduction operation (usually summation, <span class="math inline">\(F\)</span>) is applied to all tensors.</li>
<li><strong>Output:</strong> The result of the reduction (the global gradient <span class="math inline">\(\sum \nabla \Phi_i\)</span>) is made available on <strong>all</strong> GPUs.</li>
</ul>
<p align="center">
<img src="assets/all_reduce.png" alt="All Reduce" width="70%">
</p>
<p>Once every node receives the global gradient, it performs the <strong><code>optimizer.step()</code></strong> operation independently, ensuring all model copies remain in <code>sync</code>. These collective operations are defined in the <strong><code>torch.distributed</code></strong> API.</p>
<p>Here I’ve a machine with 4 T4 GPUs.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">ray@ip-10-0-69-225:code$</span> nvidia-smi <span class="at">-L</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="ex">GPU</span> 0: Tesla T4 <span class="er">(</span><span class="ex">UUID:</span> GPU-31a1b562-c769-c7f1-ede1-48847cec8d53<span class="kw">)</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="ex">GPU</span> 1: Tesla T4 <span class="er">(</span><span class="ex">UUID:</span> GPU-1beaf204-f6f7-182d-67f8-aee6c58128df<span class="kw">)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="ex">GPU</span> 2: Tesla T4 <span class="er">(</span><span class="ex">UUID:</span> GPU-934ca246-df7e-2c7f-4bdd-b07859e46b2d<span class="kw">)</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="ex">GPU</span> 3: Tesla T4 <span class="er">(</span><span class="ex">UUID:</span> GPU-141171cb-db62-b770-97ff-955f8c7f2265<span class="kw">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Now let’s create a simple example to demonstrate the <strong>All-Reduce</strong> operation by creating a tensor on each of the 4 GPUs and performing the <strong>All-Reduce</strong> operation on them.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true" href="">dist_all_reduce.py</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.distributed <span class="im">as</span> dist</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_process():</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initializes the process group using the efficient nccl backend</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    dist.init_process_group(backend<span class="op">=</span><span class="st">'nccl'</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    torch.cuda.set_device(dist.get_rank())</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> example_all_reduce():</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    tensor <span class="op">=</span> torch.tensor([dist.get_rank() <span class="op">+</span> <span class="dv">1</span>] <span class="op">*</span> <span class="dv">3</span>, dtype<span class="op">=</span>torch.float32).cuda()</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Before all_reduce on rank </span><span class="sc">{</span>dist<span class="sc">.</span>get_rank()<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>tensor<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    dist.all_reduce(tensor, op<span class="op">=</span>dist.ReduceOp.SUM)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"After all_reduce on rank </span><span class="sc">{</span>dist<span class="sc">.</span>get_rank()<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>tensor<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the process group and set the device, create a tensor on each GPU and perform the All-Reduce operation on them.</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>init_process()</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>example_all_reduce()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p>We can run this code on 4 GPUs using <code>torchrun</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">torchrun</span> <span class="at">--nproc_per_node</span><span class="op">=</span>4 dist_all_reduce.py</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>We will get the following output:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> all_reduce on rank 3: tensor<span class="er">(</span><span class="ex">[4.,</span> 4., 4.], device=<span class="st">'cuda:3'</span><span class="kw">)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> all_reduce on rank 0: tensor<span class="er">(</span><span class="ex">[1.,</span> 1., 1.], device=<span class="st">'cuda:0'</span><span class="kw">)</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> all_reduce on rank 2: tensor<span class="er">(</span><span class="ex">[3.,</span> 3., 3.], device=<span class="st">'cuda:2'</span><span class="kw">)</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> all_reduce on rank 1: tensor<span class="er">(</span><span class="ex">[2.,</span> 2., 2.], device=<span class="st">'cuda:1'</span><span class="kw">)</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> all_reduce on rank 3: tensor<span class="er">(</span><span class="ex">[10.,</span> 10., 10.], device=<span class="st">'cuda:3'</span><span class="kw">)</span> </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> all_reduce on rank 0: tensor<span class="er">(</span><span class="ex">[10.,</span> 10., 10.], device=<span class="st">'cuda:0'</span><span class="kw">)</span> </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> all_reduce on rank 2: tensor<span class="er">(</span><span class="ex">[10.,</span> 10., 10.], device=<span class="st">'cuda:2'</span><span class="kw">)</span> </span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> all_reduce on rank 1: tensor<span class="er">(</span><span class="ex">[10.,</span> 10., 10.], device=<span class="st">'cuda:1'</span><span class="kw">)</span> </span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="overlapping-communication-and-computation" class="level3">
<h3 class="anchored" data-anchor-id="overlapping-communication-and-computation">Overlapping Communication and Computation</h3>
<p>In a naive/vanilla DP implementation, the GPUs sit <strong>idle</strong> during the communication phase, as the <strong>All-Reduce</strong> operation begins only after <strong>all</strong> gradients are computed in the backward pass. This is inefficient.</p>
<p align="center">
<img src="assets/all_reduce.gif" alt="All Reduce" width="100%">
</p>
<p>To eliminate this idle time, we try to <strong>overlap</strong> the communication and computation as much as possible.</p>
<ul>
<li><strong>Method:</strong> As soon as the gradient for a specific layer is computed during the backward pass (e.g., <span class="math inline">\(\nabla L_2\)</span>), we immediately trigger the <strong>All-Reduce</strong> for that gradient <strong>in the background</strong>.</li>
<li><strong>Rationale:</strong> The computation of the next layer’s gradient (<span class="math inline">\(\nabla L_1\)</span>) is independent of the communication of the previous layer’s gradient (<span class="math inline">\(\nabla L_2\)</span>).</li>
<li><strong>Implementation:</strong> This technique is implemented via <strong>hooks</strong> in PyTorch (like <code>post_accumulate_grad_hook()</code>), allowing the next computation step to proceed while the communication step runs concurrently, significantly improving throughput. It attaches an <code>all-reduce hook function</code> to each parameter that requires gradients. With this implementation, it communicates more frequently but in smaller packets.</li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true" href="">Overlapping Communication and Computation</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> register_backward_hook(<span class="va">self</span>, hook):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Registers a backward hook for all parameters of the model that </span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">    require gradients.</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.module.parameters():</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> p.requires_grad <span class="kw">is</span> <span class="va">True</span>:</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>            p.register_post_accumulate_grad_hook(hook)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p>Previously, while communication was happening, we had to <strong>wait</strong> for all the gradients to be computed in the backward pass.</p>
<p align="center">
<img src="assets/dp_overlap1.png" alt="All Reduce" width="100%">
</p>
<p>But now, we are <strong>overlapping</strong> the communication and computation. So, we are not <strong>waiting</strong> for all the gradients to be computed in the backward pass. We are computing the gradients for the next layer while the communication for the previous layer is happening.</p>
<p align="center">
<img src="assets/dp_overlap2.png" alt="All Reduce" width="100%">
</p>
<p>We can, in fact, do even better and communicate more efficiently by grouping the gradients into larger buckets and performing the <strong>All-Reduce</strong> operation on these buckets.</p>
<p>It’s like packing items into boxes before shipping. (Have you noticed that, when placing an order on Amazon, they sometimes offer to pack multiple items into a single box to save on shipping costs? That’s exactly what we’re doing here, but with <strong>gradients</strong>.)</p>
<p>With this approach, we can significantly reduce communication overhead and speed up computation.</p>
<p align="center">
<img src="assets/dp_overlap3.png" alt="All Reduce" width="100%">
</p>
</section>
</section>
<section id="the-limitations-of-simple-data-parallelism-dp" class="level2">
<h2 class="anchored" data-anchor-id="the-limitations-of-simple-data-parallelism-dp">The Limitations of Simple Data Parallelism (DP)</h2>
<p>Now that we’ve explored how to scale up training on multiple GPUs using Data Parallelism, a natural question arises: does this scaling result in perfect, linear performance gains? In other words, do we get proportional speedup as we add more GPUs?</p>
<p>The reality is more nuanced. Although data parallelism cleverly overlaps the all-reduce gradient synchronization with backward computation, these efficiency gains don’t hold up indefinitely. As the number of GPUs increases, into the hundreds or thousands, the cost of coordination and the demands on the networking infrastructure start to rise quickly. Eventually, with each additional GPU, the improvements in throughput diminish, and the overall system efficiency drops.</p>
<p align="center">
<img src="assets/dp_perf.png" alt="Data Parallelism Limitations" width="100%">
</p>
<p>The chart above shows that as we add GPUs, <strong>throughput degrades noticeably</strong>, even though the <strong>memory usage per GPU remains unchanged</strong> regardless of the number of data parallel workers.</p>
<p>Data parallelism was our first (simple) strategy to scale training across more GPUs.</p>
<p>However, our discussion so far has rested on the assumption that the <strong>entire model</strong> fits comfortably within the memory of a single GPU. But what happens when models grow so large (such as GPT-3, with 175 billion parameters) that they can no longer fit into one GPU’s memory (e.g., an NVIDIA A100 with 80GB of RAM)?</p>
<p align="center">
<img src="assets/model_hw.png" alt="Model Exceeds GPU Memory" width="50%">
</p>
<p>As model sizes grow, it becomes common that a single accelerator (GPU in our case) cannot contain all model parameters, optimizer states, and gradients. Therefore, we need to find additional ways to scale training beyond simple DP, which can allow us to train models that <strong>don’t fit on a single GPU</strong>.</p>
<p>And that is what we will discuss in the next section - <strong>ZeRO</strong> (Zero Redundancy Optimizer).</p>
</section>
<section id="zero-zero-redundancy-optimizer" class="level1">
<h1>ZeRO: Zero Redundancy Optimizer</h1>
<p>ZeRO (Zero Redundancy Optimizer) is a family of techniques that addresses constrain of <strong>static memory</strong> (<code>parameters</code>, <code>gradients</code>, <code>optimizer states</code>) on a single GPU. With ZeRO, we can train models that don’t fit on a single GPU, and it does that by <strong>sharding</strong> the static memory components across multiple GPUs.</p>
<p>This approach is organized into three possible optimization stages:</p>
<ul>
<li><strong>ZeRO-1</strong>: optimizer state sharding</li>
<li><strong>ZeRO-2</strong>: optimizer state + gradient sharding</li>
<li><strong>ZeRO-3</strong>: optimizer state + gradient + parameter sharding</li>
</ul>
<p align="center">
<img src="assets/zero.png" alt="ZeRO" width="100%">
</p>
<p>Without even going further, you can probably guess that, with this approch we need to do a <code>lot of communication</code> between the GPUs.</p>
<p>But as we have seen in the previous section, we can overlap the communication and computation to some extent. So, we can reduce the communication overhead by overlapping the communication and computation.</p>
<p>Let’s discuss each of these techniques in detail, starting with <strong>ZeRO-1</strong>.</p>
<section id="zero-1-sharding-optimizer-states" class="level3">
<h3 class="anchored" data-anchor-id="zero-1-sharding-optimizer-states">ZeRO-1: Sharding <code>Optimizer States</code></h3>
<p>Recall from our earlier discussion, the <strong>static memory footprint</strong> per GPU specifically for <strong>mixed precision (using BF16 + FP32)</strong>:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Memory Component</th>
<th style="text-align: left;">Precision</th>
<th style="text-align: left;">Size (<span class="math inline">\(\Psi\)</span> Bytes)</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Model Parameters</td>
<td style="text-align: left;">BF16 (2 bytes)</td>
<td style="text-align: left;"><span class="math inline">\(2\Psi\)</span></td>
<td style="text-align: left;">Used for forward and backward passes</td>
</tr>
<tr class="even">
<td style="text-align: left;">Parameter Gradients</td>
<td style="text-align: left;">BF16 (2 bytes)</td>
<td style="text-align: left;"><span class="math inline">\(2\Psi\)</span></td>
<td style="text-align: left;">Used in backpropagation</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Master Weights</td>
<td style="text-align: left;">FP32 (4 bytes)</td>
<td style="text-align: left;"><span class="math inline">\(4\Psi\)</span></td>
<td style="text-align: left;">Full precision copy for the update step</td>
</tr>
<tr class="even">
<td style="text-align: left;">Optimizer States (Adam)</td>
<td style="text-align: left;">FP32 (4+4 bytes)</td>
<td style="text-align: left;"><span class="math inline">\(8\Psi\)</span></td>
<td style="text-align: left;">Stores 1st and 2nd moment estimates (<span class="math inline">\(4\Psi\)</span> each)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Total Static Memory (with Mixed Precision)</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong><span class="math inline">\(16\Psi\)</span></strong></td>
<td style="text-align: left;"><strong>The absolute floor for static storage</strong></td>
</tr>
</tbody>
</table>
<p>The largest part of the static memory comes from the <strong>optimizer states</strong>, especially for optimizers like Adam, which maintain both first and second moment statistics.</p>
<p><strong>With DP</strong>, all these components are duplicated on every GPU in the data-parallel group, so each device bears the full cost (<span class="math inline">\(16\Psi\)</span>) of these tensors (ignoring activations for now).</p>
<div class="callout callout-style-default callout-note callout-titled" title="Important Caveat: Master Weights Are Part of Optimizer State Sharding">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Important Caveat: Master Weights Are Part of Optimizer State Sharding
</div>
</div>
<div class="callout-body-container callout-body">
<p>When discussing the sharding of optimizer states in ZeRO, we must also include the <strong>master weights</strong> (the FP32 copy of model parameters used for the optimizer update) in the sharding calculation. Both the optimizer states and these master weights are stored in FP32, and both are sharded together in ZeRO-1.</p>
<p>Thus, when you see references to <code>optimizer state sharding</code>, this always implicitly includes <strong>master weights</strong> in modern mixed precision training setups.</p>
</div>
</div>
<p>With <strong>ZeRO-1</strong>, the goal is to <strong>shard</strong> (that is, partition and spread) the <strong>FP32 optimizer states</strong> and <strong>FP32 master weights</strong> across the <span class="math inline">\(N_d\)</span> GPUs, rather than storing them fully on each device. This introduces the following changes:</p>
<ul>
<li>Every GPU stores only a <span class="math inline">\(\frac{1}{N_d}\)</span>th slice of the <code>optimizer states</code> (<span class="math inline">\(8\Psi\)</span>) and <code>master weights</code> (<span class="math inline">\(4\Psi\)</span>), rather than the full <span class="math inline">\(12\Psi\)</span>.</li>
<li>The <code>parameters</code> and <code>gradients</code> tensors (in BF16) remain fully replicated on each GPU for compatibility with forward and backward passes.</li>
</ul>
<p align="center">
<img src="assets/zero-1.png" alt="ZeRO-1" width="100%">
</p>
<p>The resulting <strong>static memory footprint per GPU</strong> with ZeRO-1 sharding thus becomes: <span class="math display">\[
\mathcal{M}_{\text{ZeRO-1}} = 2\Psi + 2\Psi + \frac{12\Psi}{N_d}
\]</span></p>
<ul>
<li>Parameters (BF16): <span class="math inline">\(2\Psi\)</span></li>
<li>Gradients (BF16): <span class="math inline">\(2\Psi\)</span></li>
<li>Optimizer States + Master Weights (FP32): <span class="math inline">\(\frac{12\Psi}{N_d}\)</span></li>
</ul>
<p>Just to make this more concrete, let’s look at some practical numbers. Suppose you have a modern <strong>A100/H100 GPU</strong> with <strong>80GB</strong> of memory. In DP, the largest model you can fit is roughly:</p>
<p><span class="math display">\[
\text{Max Parameters (DP)} = \frac{80~\text{GB}}{16~\text{bytes per param}} \approx 5~\text{billion parameters}
\]</span></p>
<p>But if you apply ZeRO-1 with <strong>64 GPUs</strong> (<span class="math inline">\(N_d = 64\)</span>), the optimizer states and master weights are now only a small shard per GPU:</p>
<ul>
<li><span class="math inline">\(\frac{12}{64} \approx 0.1875\)</span> (so just 1.5GB of optimizer/master weights per GPU for a 5B model)</li>
<li>The effective static memory per parameter drops from <strong>16 bytes</strong> (DP) to about <strong>4.2 bytes</strong> (ZeRO-1).</li>
</ul>
<p>So now, the largest model you can train on that same 80GB GPU jumps to:</p>
<p><span class="math display">\[
\text{Max Parameters (ZeRO-1, 64 GPUs)} = \frac{80~\text{GB}}{4.2~\text{bytes per param}} \approx 19~\text{billion parameters}
\]</span></p>
<p>So, it’s great that we can train a larger model on the same hardware, but we still need to discuss the communication overhead involved in this approach.</p>
<p>For the <code>forward pass</code>, we <strong>don’t</strong> need to do any communication, as we have all the parameters in each GPU.</p>
<p align="center">
<img src="assets/zero-1_1.png" alt="ZeRO-1 Backward" width="100%">
</p>
<p>During the <code>backward pass</code>, each GPU computes gradients for all parameters, so every GPU holds a full copy of the gradients. To ensure the gradients are synchronized across all GPUs, we perform an <strong>All-Reduce</strong> operation. After this step, all GPUs have identical, synchronized gradients.</p>
<p align="center">
<img src="assets/zero-1_2.png" alt="ZeRO-1 Backward" width="100%">
</p>
<p>But now, on each GPU, we can <em>discard</em> all gradients except the one corresponding to the optimizer state stored on that particular GPU, and <em>keep only that one</em>.</p>
<p align="center">
<img src="assets/zero-1_3.png" alt="ZeRO-1 Backward" width="100%">
</p>
<p>After this, each GPU can <em>update</em> its respective model parameters to its corresponding optimizer state and gradients.</p>
<p align="center">
<img src="assets/zero-1_4.png" alt="ZeRO-1 Backward" width="100%">
</p>
<p>At this point, we need to communicate again to ensure that all GPUs have the updated model parameters. After the update step, each GPU holds the updated parameters only for its own shard of the optimizer state.</p>
<p>But what type of communication do we need to do ?</p>
<p>Each GPU needs to <em>gather</em> the updated model parameters from all the other GPUs. For this, we perform an <strong>All-Gather</strong> operation, which is another communication primitive similar to <strong>All-Reduce</strong> that we’ve seen earlier.</p>
<p align="center">
<img src="assets/all_gather.png" alt="All Gather" width="70%">
</p>
<p>Let’s quickly see an example of how to do this using <code>torch.distributed.all_gather()</code>. Here we are creating a tensor on each GPU and performing the <strong>All-Gather</strong> operation on these tensors.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true" href="">dist_all_gather.py</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.distributed <span class="im">as</span> dist</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_process():</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initializes the process group using the efficient nccl backend</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    dist.init_process_group(backend<span class="op">=</span><span class="st">'nccl'</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    torch.cuda.set_device(dist.get_rank())</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> example_all_gather():</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    tensor <span class="op">=</span> torch.tensor([dist.get_rank() <span class="op">+</span> <span class="dv">1</span>] <span class="op">*</span> <span class="dv">3</span>, dtype<span class="op">=</span>torch.float32).cuda()</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prepare an output list of tensors for all_gather</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    world_size <span class="op">=</span> dist.get_world_size()</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    gathered <span class="op">=</span> [torch.zeros_like(tensor) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(world_size)]</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Before all_gather on rank </span><span class="sc">{</span>dist<span class="sc">.</span>get_rank()<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>tensor<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    dist.all_gather(gathered, tensor)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"After all_gather on rank </span><span class="sc">{</span>dist<span class="sc">.</span>get_rank()<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>[t.cpu().tolist() <span class="cf">for</span> t <span class="kw">in</span> gathered]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the process group and set the device, create a tensor on each GPU and perform the All-Gather operation on them.</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>init_process()</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>example_all_gather()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p>Just like before, we can run this code with 4 GPUs using <code>torchrun</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="ex">torchrun</span> <span class="at">--nproc_per_node</span><span class="op">=</span>4 dist_all_gather.py</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>We will get the following output:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> all_gather on rank 2: tensor<span class="er">(</span><span class="ex">[3.,</span> 3., 3.], device=<span class="st">'cuda:2'</span><span class="kw">)</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> all_gather on rank 0: tensor<span class="er">(</span><span class="ex">[1.,</span> 1., 1.], device=<span class="st">'cuda:0'</span><span class="kw">)</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> all_gather on rank 1: tensor<span class="er">(</span><span class="ex">[2.,</span> 2., 2.], device=<span class="st">'cuda:1'</span><span class="kw">)</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> all_gather on rank 3: tensor<span class="er">(</span><span class="ex">[4.,</span> 4., 4.], device=<span class="st">'cuda:3'</span><span class="kw">)</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> all_gather on rank 0: [[1.0, 1.0, 1.0], [2.0, 2.0, 2.0], [3.0, 3.0, 3.0], [4.0, 4.0, 4.0]]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> all_gather on rank 1: [[1.0, 1.0, 1.0], [2.0, 2.0, 2.0], [3.0, 3.0, 3.0], [4.0, 4.0, 4.0]]</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> all_gather on rank 2: [[1.0, 1.0, 1.0], [2.0, 2.0, 2.0], [3.0, 3.0, 3.0], [4.0, 4.0, 4.0]]</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> all_gather on rank 3: [[1.0, 1.0, 1.0], [2.0, 2.0, 2.0], [3.0, 3.0, 3.0], [4.0, 4.0, 4.0]]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>With that, each GPU now has the updated model parameters. They can now begin the next batch, performing the forward pass with these updated parameters, allowing training to continue.</p>
<p align="center">
<img src="assets/zero-1_5.png" alt="ZeRO-1 Backward" width="100%">
</p>
<p>So, this is how ZeRO-1 strategy works.</p>
<p>Now, if go back and carefully look after <em>All_Reduce</em> operation in ZeRO-1, each GPU <strong>discarded</strong> all the other gradients and <strong>kept only</strong> the one whose corresponding optimizer state is present on that particular GPU.</p>
<p>Which makes us think, why we need to keep all the gradients in all the GPUs in the first place ? Why can’t we shard the gradients as well along with its corresponding optimizer state? And this is exactly what ZeRO-2 strategy does.</p>
</section>
<section id="zero-2-sharding-gradients" class="level3">
<h3 class="anchored" data-anchor-id="zero-2-sharding-gradients">ZeRO-2: Sharding <code>Gradients</code></h3>
<p>With ZeRO-2, we further <strong>shard</strong> the <code>gradients</code> right alongside the <code>optimizer states</code>. So, each GPU now only needs to store the gradient shard <strong>corresponding</strong> to its optimizer state shard.</p>
<p align="center">
<img src="assets/zero-2.png" alt="ZeRO-2" width="100%">
</p>
<p>Just as we did for ZeRO-1, let’s run the numbers for ZeRO-2 sharding to see the dramatic benefits. With ZeRO-2, the memory formula per GPU now becomes: <span class="math display">\[
\mathcal{M}_{\text{ZeRO-2}} = 2\Psi + \frac{2\Psi + 12\Psi}{N_d}
\]</span></p>
<ul>
<li>Parameters (BF16): <span class="math inline">\(2\Psi\)</span></li>
<li>Gradients (BF16): <span class="math inline">\(\frac{2\Psi}{N_d}\)</span></li>
<li>Optimizer States + Master Weights (FP32): <span class="math inline">\(\frac{12\Psi}{N_d}\)</span></li>
</ul>
<p>If we again use an <strong>A100/H100 GPU</strong> with <strong>80GB</strong> of memory, and <span class="math inline">\(N_d = 64\)</span> GPUs, then the largest model we can train would be:</p>
<p><span class="math display">\[
\text{Max Parameters (ZeRO-2, 64 GPUs)} = \frac{80~\text{GB}}{2.2~\text{bytes per param}} \approx 36~\text{billion parameters}
\]</span></p>
<p>Let’s put this side-by-side:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Strategy</th>
<th>Effective Bytes/Param</th>
<th>Max Model on 80GB GPU</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>DP</strong></td>
<td>16</td>
<td>~5B</td>
</tr>
<tr class="even">
<td><strong>ZeRO-1</strong></td>
<td>4.2</td>
<td>~19B</td>
</tr>
<tr class="odd">
<td><strong>ZeRO-2</strong></td>
<td>2.2</td>
<td>~36B</td>
</tr>
</tbody>
</table>
<p>So, <strong>ZeRO-2</strong> nearly doubles the maximum trainable model size compared to <strong>ZeRO-1</strong> (and over 7x compared to vanilla DP). Let’s see how the communication overhead changes with ZeRO-2.</p>
<p>For the <code>forward pass</code>, we <strong>don’t</strong> need to do any communication (like in ZeRO-1), as we have all the parameters in each GPU.</p>
<p align="center">
<img src="assets/zero-2_1.png" alt="ZeRO-2 Backward" width="100%">
</p>
<p>Next, in the <code>backward pass</code>, instead of performing an <strong>All-Reduce</strong> over the gradients, we perform a <strong>Reduce-Scatter</strong> operation. This is another communication primitive, similar to <strong>All-Reduce</strong> and <strong>All-Gather</strong>, which we encountered earlier.</p>
<p align="center">
<img src="assets/zero-2_2.png" alt="ZeRO-2 Backward" width="100%">
</p>
<p>So what <strong>Reduce-Scatter</strong> operation does internally is, its first reducing (summing) the gradients across all the GPUs and then scattering the result to the GPUs that need to have the gradient shard.</p>
<p align="center">
<img src="assets/reduce_scatter.png" alt="Reduce Scatter" width="100%">
</p>
<div class="callout callout-style-default callout-note callout-titled" title="Computation-communication timeline">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Computation-communication timeline
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>ZeRO-1</strong>: We keep a copy of all gradients.</li>
<li><strong>ZeRO-2</strong>: Communicate and release the gradients on the fly.</li>
<li>In practice, both use <strong><code>reduce-scatter</code></strong> for gradients and <strong><code>all-gather</code></strong> for FP32 copy of parameters.</li>
<li>There is no real overhead to using ZeRO-2 over ZeRO-1 besides implementation complexity, and indeed <strong>ZeRO-2 is usually the better option</strong>.</li>
</ul>
</div>
</div>
<p>We can see how this works with an example.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true" href="">dist_reduce_scatter.py</a></li></ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.distributed <span class="im">as</span> dist</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_process():</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initializes the process group using the efficient nccl backend</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    dist.init_process_group(backend<span class="op">=</span><span class="st">'nccl'</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    torch.cuda.set_device(dist.get_rank())</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> example_reduce_scatter():</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    rank <span class="op">=</span> dist.get_rank()</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    world_size <span class="op">=</span> dist.get_world_size()</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Construct a single input tensor, then split into equal chunks (one for each rank)</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    input_tensor <span class="op">=</span> torch.arange(<span class="dv">1</span>, world_size <span class="op">*</span> <span class="dv">3</span> <span class="op">+</span> <span class="dv">1</span>, dtype<span class="op">=</span>torch.float32).cuda()</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    input_list <span class="op">=</span> <span class="bu">list</span>(torch.chunk(input_tensor, world_size))</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    output_tensor <span class="op">=</span> torch.zeros(<span class="dv">3</span>, dtype<span class="op">=</span>torch.float32).cuda()</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Before reduce_scatter on rank </span><span class="sc">{</span>rank<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>[t.cpu().tolist() <span class="cf">for</span> t <span class="kw">in</span> input_list]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    dist.reduce_scatter(output_tensor, input_list, op<span class="op">=</span>dist.ReduceOp.SUM)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"After reduce_scatter on rank </span><span class="sc">{</span>rank<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>output_tensor<span class="sc">.</span>cpu()<span class="sc">.</span>tolist()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the process group and set device, then perform Reduce-Scatter</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>init_process()</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>example_reduce_scatter()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p>Just like before, we can run this code with 4 GPUs using <code>torchrun</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ex">torchrun</span> <span class="at">--nproc_per_node</span><span class="op">=</span>4 dist_reduce_scatter.py</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>We will get the following output:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> reduce_scatter on rank 0: [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> reduce_scatter on rank 1: [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> reduce_scatter on rank 2: [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="ex">Before</span> reduce_scatter on rank 3: [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> reduce_scatter on rank 0: [4.0, 8.0, 12.0]</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> reduce_scatter on rank 1: [16.0, 20.0, 24.0]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> reduce_scatter on rank 2: [28.0, 32.0, 36.0]</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="ex">After</span> reduce_scatter on rank 3: [40.0, 44.0, 48.0]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Each GPU starts with identical chunked inputs. After <code>reduce_scatter</code>, every GPU gets the sum (across all GPUs) of the <em>i-th chunk</em>, distributed such that GPU 0 gets chunk 0’s sum, GPU 1 gets chunk 1’s sum, etc.</p>
<p>After <strong>Reduce-Scatter</strong> operation, each GPU now has the gradient shard corresponding to its optimizer state shard which it can use to update its respective model parameters.</p>
<p align="center">
<img src="assets/zero-2_3.png" alt="ZeRO-2 Backward" width="100%">
</p>
<p>At this stage, we need to communicate once more to share the updated model parameters across all GPUs. This is because, after applying local updates, each GPU holds the updated parameters only for its own optimizer state shard.</p>
<p align="center">
<img src="assets/zero-2_4.png" alt="ZeRO-2 Backward" width="100%">
</p>
<p>This is how ZeRO-2 strategy works.</p>
<p>We have come a long way from the vanilla DP to ZeRO-2, where we have reduced the memory footprint quite significantly, but can we further scale ? Of course we can, and this is exactly what we do in ZeRO-3.</p>
</section>
<section id="zero-3-sharding-parameters" class="level3">
<h3 class="anchored" data-anchor-id="zero-3-sharding-parameters">ZeRO-3: Sharding <code>Parameters</code></h3>
<p>ZeRO-3 is the most aggressive form of ZeRO, it shards (as you might have guessed, by now) all the static memory components: <code>parameters</code>, <code>gradients</code>, and <code>optimizer states</code>.</p>
<p>So, each GPU now only needs to store the parameter shard corresponding to its optimizer state shard.</p>
<p align="center">
<img src="assets/zero-3.png" alt="ZeRO-3" width="100%">
</p>
<div class="callout callout-style-default callout-note callout-titled" title="ZeRO-3 vs. FSDP">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>ZeRO-3 vs.&nbsp;FSDP
</div>
</div>
<div class="callout-body-container callout-body">
<p>You may have seen the terms <strong>ZeRO-3</strong> and <strong>Fully Sharded Data Parallel (FSDP)</strong> used almost interchangeably in literature, blogs, and PyTorch documentation. That’s because the underlying strategy is the same: shard parameters, gradients, and optimizer states across GPUs to minimize memory usage per device.</p>
<ul>
<li><strong>ZeRO-3</strong> originated as a theoretical memory optimization described in the <a href="https://arxiv.org/abs/1910.02054">Microsoft DeepSpeed ZeRO paper</a>, outlining <strong>stage 3</strong> of ZeRO by sharding all model state across different GPUs. Its basically a concept implemented in multiple frameworks like DeepSpeed, etc.</li>
<li><strong>FSDP (Fully Sharded Data Parallel)</strong> is the official PyTorch implementation of this idea. FSDP leverages the ZeRO-3 approach and provides a flexible interface for applying parameter, gradient, and optimizer sharding with PyTorch models in both research and production environments.</li>
</ul>
</div>
</div>
<p>With ZeRO-3, the memory formula per GPU now becomes: <span class="math display">\[
\mathcal{M}_{\text{ZeRO-3}} = \frac{2\Psi + 2\Psi + 12\Psi}{N_d} = \frac{16\Psi}{N_d}
\]</span></p>
<ul>
<li>Parameters (BF16): <span class="math inline">\(\frac{2\Psi}{N_d}\)</span></li>
<li>Gradients (BF16): <span class="math inline">\(\frac{2\Psi}{N_d}\)</span></li>
<li>Optimizer States + Master Weights (FP32): <span class="math inline">\(\frac{12\Psi}{N_d}\)</span></li>
</ul>
<p>If we again use an <strong>A100/H100 GPU</strong> with <strong>80GB</strong> of memory, and <span class="math inline">\(N_d = 64\)</span> GPUs, then the largest model we can train would be:</p>
<p><span class="math display">\[
\text{Max Parameters (ZeRO-3, 64 GPUs)} = \frac{80~\text{GB}}{0.25~\text{bytes per param}} \approx 320~\text{billion parameters}
\]</span></p>
<p>Let’s put this all side-by-side again:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Strategy</th>
<th>Effective Bytes/Param</th>
<th>Max Model on 80GB GPU</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>DP</strong></td>
<td>16</td>
<td>~5B</td>
</tr>
<tr class="even">
<td><strong>ZeRO-1</strong></td>
<td>4.2</td>
<td>~19B</td>
</tr>
<tr class="odd">
<td><strong>ZeRO-2</strong></td>
<td>2.2</td>
<td>~36B</td>
</tr>
<tr class="even">
<td><strong>ZeRO-3</strong></td>
<td>0.25</td>
<td>~320B</td>
</tr>
</tbody>
</table>
<p>As you can see, <strong>ZeRO-3/FSDP</strong> increases the maximum trainable model size by a factor of 10 compared to <strong>ZeRO-2</strong>, and by more than 60 times compared to <strong>vanilla DP</strong>.</p>
<p>Now, let’s see how the communication overhead changes with ZeRO-3.</p>
<p>As the model parameters are now sharded, we have a problem, we can not do the <code>forward pass</code> without any communication, we need to do a <strong>All-Gather</strong> operation to first get the full model parameters on all the GPUs.</p>
<p align="center">
<img src="assets/zero-3_1.png" alt="ZeRO-3 Forward" width="100%">
</p>
<p>But after the <code>forward pass</code>, we can <em>flush</em> the model parameters from memory, as we don’t need them anymore for the current forward pass (as we can see above). So, although it reduces the memory footprint, it introduces a communication overhead.</p>
<p>Similarly in the <code>backward pass</code>, we need to gather the parameters as and when needed using <strong>All-Gather</strong> and then perform <strong>Reduce-Scatter</strong> operation to get the gradient shards on all the GPUs as we did in ZeRO-2.</p>
<p align="center">
<img src="assets/zero-3_2.png" alt="ZeRO-3 Backward" width="100%">
</p>
<div class="callout callout-style-default callout-note callout-titled" title="ZeRO-3 Communication and Memory Recap">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>ZeRO-3 Communication and Memory Recap
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let’s recap how communication and memory work with ZeRO-3.</p>
<p>For the <code>forward pass</code>, since the parameters are fully sharded, we have to <strong>all-gather</strong> the weights whenever we need them, which gives us a communication cost of <span class="math inline">\(\Psi\)</span>. Because those parameters can be released from memory right after the forward usage, we have to <strong>all-gather</strong> again as needed in the <code>backward pass</code>, so we pay that <span class="math inline">\(\Psi\)</span> “tax” a second time.</p>
<p>And just like ZeRO-2, we need a <strong>reduce-scatter</strong> for the gradients at the end of <code>backward pass</code>, which adds yet another <span class="math inline">\(\Psi\)</span> in communication cost. So in total, the communication bill per iteration comes out to <span class="math inline">\(3\Psi\)</span>, a bit higher than the <span class="math inline">\(2\Psi\)</span> we saw in ZeRO-2.</p>
<p>On paper, this sounds like a lot of data being moved around, but in practice it’s not too scary! Thanks to <strong>prefetching</strong>, we can overlap these all-gather operations with computation.</p>
<p>Typically, while we’re doing the forward for Layer <span class="math inline">\(n\)</span>, we can start all-gathering the parameters for Layer <span class="math inline">\(n+1\)</span> in parallel.</p>
<p>Similarly, during the <code>backward pass</code>, we can prefetch the next set of weights needed. This overlap keeps things efficient as long as we aren’t cranking DP up to very large scales (as a rough guideline, keeping DP <span class="math inline">\(\leq\)</span> 512 is usually safe).</p>
<p>From the memory perspective, by sharding everything, we’ve boiled the formula down to its most compact form:</p>
<p><span class="math display">\[
\mathcal{M}_{\text{ZeRO-3}} = \frac{2\Psi + 2\Psi + 12\Psi}{N_d}
\]</span> Increasing the DP group size keeps reducing per-GPU model memory, but activation memory still requires tricks like checkpointing and grad accumulation, which we discussed earlier.</p>
</div>
</div>
<p>One important point that can be confusing at first: Even though <strong>ZeRO-1</strong>, <strong>ZeRO-2</strong>, and <strong>ZeRO-3</strong> all shard the model, they are still forms of <strong>DP</strong>.</p>
<p>Each GPU still processes the entire forward and backward pass of the model on its own batch of data, just like vanilla DP. The main difference is that <strong>ZeRO</strong> <code>changes</code> how the model’s <code>parameters</code> and <code>related tensors</code> are stored and managed across GPUs, which dramatically reduces memory usage but doesn’t change the core idea of <strong>DP</strong>.</p>
<p align="center">
<img src="assets/dp_summary.png" alt="DP Summary" width="100%">
</p>
</section>
</section>
<section id="introduction-to-ray---unified-ai-compute-engine" class="level1">
<h1>Introduction to Ray - <code>Unified AI Compute Engine</code></h1>
<p>Now that we’ve explored the <strong>ZeRO</strong> stages and different data parallel strategies, let’s discuss how to put these techniques into practice using <strong>Ray</strong> and <strong>PyTorch</strong>, and why <strong>Ray</strong> is such a good fit for large-scale distributed training in real-world settings.</p>
<p>Until now, we’ve mostly focused on how to leverage multiple GPUs within a single machine. However, scaling up modern deep learning requires distributing the training job not just across several GPUs, but often across many different machines as well.</p>
<p>This introduces a host of new challenges from launching and configuring clusters, to monitoring jobs, handling failures, and minimizing the engineering overhead when scaling up and down.</p>
<p>When moving to <strong>distributed training</strong> at scale, several key requirements and challenges emerge in practice:</p>
<ul>
<li><strong>Scalability and Speed:</strong> Training jobs should be able to leverage more GPUs and machines to finish faster, without painful setup.</li>
<li><strong>Easy Infrastructure Management:</strong> We shouldn’t need to spend time manually setting up or configuring clusters, whether on cloud or on-premises resources.</li>
<li><strong>Visibility and Monitoring:</strong> It must be easy to track metrics, logs, and failures across all nodes, so debugging and monitoring don’t turn into a bottleneck.</li>
<li><strong>Reliability and Fault Tolerance:</strong> Hardware failures, network issues, or preempted nodes shouldn’t force us to restart training from scratch, resilience and checkpointing are critical.</li>
<li><strong>Minimal Code Changes:</strong> Adapting our code for distributed training shouldn’t require a major rewrite of training logic.</li>
</ul>
<p><strong>Ray</strong> provides solutions for all of these requirements (and more), making it a compelling choice for large-scale distributed deep learning.</p>
<p>In the sections that follow, we’ll see concrete code and recipes showing how easy Ray makes it to scale PyTorch training seamlessly, from simple data parallel jobs to advanced ZeRO and FSDP setups. But before that let’s spend some time to understand what <strong>Ray</strong> is and how it works.</p>
<p><strong>Ray</strong> is an open-source, unified AI Compute Engine designed to scale Python applications, especially AI/ML workloads, from a single machine to clusters with thousands of machines, all with minimal code changes.</p>
<p>At the core of <strong>Ray</strong> is <code>Ray Core</code>, a low-level distributed computing framework which provides a simple, Pythonic API for building and scaling any distributed applications.</p>
<p align="center">
<img src="assets/ray_01.png" alt="Ray" width="100%">
</p>
<section id="ray-core-primitives" class="level2">
<h2 class="anchored" data-anchor-id="ray-core-primitives">Ray Core Primitives</h2>
<p><code>Ray Core</code> provides a minimal, yet powerful set of primitives that let you upgrade normal Python code into distributed code with almost no friction.</p>
<p align="center">
<img src="assets/ray_00.png" alt="Ray Core Primitives" width="100%">
</p>
<div class="callout callout-style-default callout-note callout-titled" title="Ray Compute Engine">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Ray Compute Engine
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Ray</strong> handles the difficult parts, like task scheduling, node failures, data transfers, and more behind the scenes so you don’t have to. As an ML engineer or researcher, you can focus on your model, algorithm, and data, while <strong>Ray</strong> takes care of the complexities of distributed systems.</p>
</div>
</div>
</section>
<section id="an-example-for-stateless-tasks-tasks" class="level2">
<h2 class="anchored" data-anchor-id="an-example-for-stateless-tasks-tasks">An example: For <code>Stateless</code> Tasks (Tasks)</h2>
<p>Let’s try to understand the core primitives of <strong>Ray</strong>, <code>tasks</code> and <code>actors</code> with an example. Imagine you’re building a simple app where you need to process a batch of images with a simple transformation (like inverting the colors).</p>
<p>At first, you write a <code>for-loop</code> to process the images sequentially. It works, but it’s sluggish, using only a single CPU core, even if your machine has lets say eight cores. What if you need to process hundreds or thousands of images? This is where <strong>Ray</strong> comes in, and a world of instant scalability.</p>
<p>Below, we walk step-by-step through the journey: from a plain, sequential Python function, which is painfully slow! to a parallel powerhouse processed by using <strong>Ray Tasks</strong>, and finally to coordinated, stateful parallelism with <strong>Ray Actors</strong>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true" href="">Step 1. Sequential Processing (Slow)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false" href="">Step 2. Parallel Ray Task (Fast)</a></li></ul>
<div class="tab-content">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<p>Each image is processed one after another, burning a whole second per image. With 8 images, that’s 8 seconds to process all the images.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sequential_process.py</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_image(image: np.ndarray) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Simulates a slow 1-second filter."""</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">1</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">255</span> <span class="op">-</span> image</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> [np.random.randint(<span class="dv">0</span>, <span class="dv">255</span>, (<span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">3</span>)) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">8</span>)]</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Sequential: 8 images × 1 sec/image = 8 seconds</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> [process_image(img) <span class="cf">for</span> img <span class="kw">in</span> images]</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Processed </span><span class="sc">{</span><span class="bu">len</span>(results)<span class="sc">}</span><span class="ss"> images in </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Our code works, but only uses a single core, leaving the rest idle. Not a good situation. Let’s try to parallelize it using <code>Ray Tasks</code>.</p>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<p>Now, let’s use Ray to parallelize the image processing.</p>
<p><strong>Ray’s</strong> <code>@ray.remote</code> decorator instantly makes your function run in parallel, one copy per available CPU core.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># parallel_process.py</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ray</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Initialize Ray - autodetects &amp; uses all available CPU cores</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>ray.init()</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Decorate the function as a remote Ray task</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="at">@ray.remote</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_image(image: np.ndarray) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Simulates a slow 1-second filter."""</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">1</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">255</span> <span class="op">-</span> image</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> [np.random.randint(<span class="dv">0</span>, <span class="dv">255</span>, (<span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">3</span>)) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">8</span>)]</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Launch tasks in parallel; returns list of ObjectRefs (futures)</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>result_refs <span class="op">=</span> [process_image.remote(img) <span class="cf">for</span> img <span class="kw">in</span> images]</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Wait for and retrieve finished results via ray.get()</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> ray.get(result_refs)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="co"># On an 8-core machine: ~1 second total runtime!</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Processed </span><span class="sc">{</span><span class="bu">len</span>(results)<span class="sc">}</span><span class="ss"> images in </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>ray.shutdown()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>What we did differently?</strong></p>
<ul>
<li>We decorated the function with <code>@ray.remote</code> decorator to make it a remote task.</li>
<li>We called the function with <code>.remote()</code> to launch it as a remote task.</li>
<li>We then wait for the results by calling <code>ray.get()</code> on the <code>ObjectRefs</code> returned by the <code>remote</code> calls.</li>
<li>The secret here is the <code>ObjectRef</code>, each <code>.remote()</code> call sends off a job in the background, while your main code keeps going. When you call <code>ray.get(result_refs)</code>, <strong>Ray</strong> assembles all results when they are ready.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Ray Speed-Up">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ray Speed-Up
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>By adding just <code>@ray.remote</code>, <code>.remote()</code>, and <code>ray.get()</code>, we get a nearly 8x speedup with 8 CPU cores.</strong></p>
</div>
</div>
</section>
<section id="going-further-for-stateful-tasks-actors" class="level2">
<h2 class="anchored" data-anchor-id="going-further-for-stateful-tasks-actors">Going Further: For <code>Stateful</code> Tasks (Actors)</h2>
<p>The beauty of Ray is that it doesn’t just parallelize our work, it also gives us the right tool for <strong>sharing state</strong> across those jobs. Imagine that you want a running tally (say, the total number of pixels processed across all images), but you can’t use a global variable, because each parallel job runs isolated.</p>
<p>What you really want is a service: <em>a live, remote counter</em> that all jobs can update in real-time. That’s what is known as an <code>Actor</code> in Ray: a class with its own persistent state, living somewhere on the cluster.</p>
<p>Let’s see how to create and use an Actor for any <code>stateful</code> task.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-9-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-1" role="tab" aria-controls="tabset-9-1" aria-selected="true" href="">Ray Actor (Stateful)</a></li></ul>
<div class="tab-content">
<div id="tabset-9-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-9-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># actor_counter.py</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ray</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>ray.init()</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Define the stateful service as a Python Class</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="at">@ray.remote</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PixelCounter:</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The internal state is defined in __init__</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.total_pixels <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># A method to mutate (update) the internal state</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add(<span class="va">self</span>, num_pixels: <span class="bu">int</span>):</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.total_pixels <span class="op">+=</span> num_pixels</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># A method to retrieve the internal state</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_total(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.total_pixels</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Modify the Task to use the Actor Handle</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="at">@ray.remote</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_image_with_actor(image: np.ndarray, counter_actor: <span class="st">"ActorHandle"</span>):</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This task calls the Actor's add method remotely</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>    counter_actor.add.remote(image.size)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">1</span>)</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The image processing logic is here, but omitted for simplicity</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Main Script ---</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> [np.random.randint(<span class="dv">0</span>, <span class="dv">255</span>, (<span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">3</span>)) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">8</span>)]</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>image_size <span class="op">=</span> images[<span class="dv">0</span>].size</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>expected_total <span class="op">=</span> image_size <span class="op">*</span> <span class="bu">len</span>(images) <span class="co"># 8 * 300 = 2400</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Create a single instance (the Actor Handle)</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>counter <span class="op">=</span> PixelCounter.remote()</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Launch 8 parallel tasks, passing the Actor Handle to each</span></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>task_refs <span class="op">=</span> [process_image_with_actor.remote(img, counter) <span class="cf">for</span> img <span class="kw">in</span> images]</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Wait for all the image processing tasks to complete</span></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>ray.get(task_refs)</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Retrieve the final state from the Actor</span></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>final_total_ref <span class="op">=</span> counter.get_total.remote()</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>final_total <span class="op">=</span> ray.get(final_total_ref)</span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Expected total pixels: </span><span class="sc">{</span>expected_total<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Actual total from actor: </span><span class="sc">{</span>final_total<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>ray.shutdown()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>What we did differently?</strong></p>
<ul>
<li>Previously, with <strong>Ray Tasks</strong>, each task independently processed an image in a <code>stateless</code> way. Now, by with the Actor (the remote <code>PixelCounter</code> class), we can safely accumulate the total pixel count as each task reports in.</li>
<li>The Actor’s state is persistent across many requests, enabling us to coordinate and aggregate information even in a distributed, parallel environment.</li>
<li>The key difference from before is that we now define a <code>@ray.remote</code> class (<code>PixelCounter</code>) and pass its handle to the tasks, so they can call <code>add.remote()</code> to update the shared state.</li>
</ul>
</div>
</div>
</div>
<p>This pattern of combining <strong>Ray Tasks</strong> for <code>stateless</code> (think of Python functions), independent work and <strong>Ray Actors</strong> for <code>stateful</code> (think of Python classes) is the foundation of scalable Python pipelines for any real-world application (not just any AI applications).</p>
<p><strong>Ray’s</strong> primitives empower us to build scalable, reliable, and maintainable distributed applications, without rewriting all our code or micro-managing threads and processes.</p>
</section>
<section id="ray-for-different-ai-workloads" class="level2">
<h2 class="anchored" data-anchor-id="ray-for-different-ai-workloads">Ray for Different AI Workloads</h2>
<p>While Ray Core provides the low-level primitives for building distributed applications, it is not the only or always the best option, especially for <strong>specialized AI workloads</strong>.</p>
<p>It also offers higher-level abstractions tailored to specific AI tasks like <code>data processing</code>, <code>training</code>, <code>hyperparameter search</code>, <code>RL</code> and <code>model serving</code>.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Ray Library</th>
<th style="text-align: left;">Purpose</th>
<th style="text-align: left;">Key Features / Benefits</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>Ray Data</code></td>
<td style="text-align: left;"><code>Scalable Data Ingest, Processing, Inference</code></td>
<td style="text-align: left;">Effortlessly shards and preprocesses massive datasets; streams data efficiently between CPUs (ETL) and GPUs (training/inference) to maximize hardware utilization.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>Ray Train</code></td>
<td style="text-align: left;"><code>Distributed Training &amp; Fine-Tuning</code></td>
<td style="text-align: left;">Abstracts away multi-node/GPU orchestration and synchronization for PyTorch, TensorFlow, etc., without the need for boilerplate or manual sync.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>Ray Tune</code></td>
<td style="text-align: left;"><code>Scalable Hyperparameter Search</code></td>
<td style="text-align: left;">Coordinates and manages hyperparameter trials (search, early stopping, scheduling) across a cluster; includes experiment tracking and best-model picking.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>Ray Serve</code></td>
<td style="text-align: left;"><code>Fast, Programmable Model Serving</code></td>
<td style="text-align: left;">Deploys models and logic as microservices with auto-scaling; supports model composition and features like traffic splitting and versioning.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>Ray RLlib</code></td>
<td style="text-align: left;"><code>Scalable Reinforcement Learning</code></td>
<td style="text-align: left;">Provides a comprehensive library for training and evaluating RL algorithms.</td>
</tr>
</tbody>
</table>
<p>These libraries are built on top of <code>Ray Core</code> and offer a more user-friendly interface for building distributed applications.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Why Use Higher-Level Ray Libraries?">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Why Use Higher-Level Ray Libraries?
</div>
</div>
<div class="callout-body-container callout-body">
<p>If Ray Core’s Tasks and Actors are this powerful, why bother with higher-level Ray libraries like Ray Train or Ray Data?</p>
<p>Simple answer is <strong>Abstraction and Specialization</strong>. While it’s technically possible to build a full distributed training pipeline with only Ray Core, that approach means you shoulder all the complexities, like manual data sharding, synchronization (e.g., for PyTorch DDP), distributed checkpointing, fault tolerance, handling resuming, and hyperparameter search. That’s a lot of boilerplate and risk!</p>
</div>
</div>
<p>It also has tight integration with popular frameworks like <code>PyTorch</code>, <code>vLLM</code>, <code>Hugging Face</code>, and more.</p>
<p align="center">
<img src="assets/ray_02.png" alt="Ray" width="100%">
</p>
<p>This unified ecosystem empowers us to build end-to-end distributed AI workflows.</p>
<p>In this blog, we’ll focus on distributed training with <code>Ray Train</code>, showing how it can scale our PyTorch training from a single GPU to a full cluster almost effortlessly.</p>
<div class="callout callout-style-default callout-warning callout-titled" title="Why Not Use Only PyTorch Distributed?">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Why Not Use Only PyTorch Distributed?
</div>
</div>
<div class="callout-body-container callout-body">
<p>While <strong>PyTorch Distributed</strong> (such as DDP) is an excellent built-in solution for multi-GPU training, it’s primarily designed for <em>single-node</em> or <em>homogeneous, tightly-coupled clusters</em>. If you’re just scaling to multiple GPUs on one machine, PyTorch’s distributed tools/APIs are often enough. And you can run your training job with <code>torchrun</code> command.</p>
<p>However, <strong>the challenges multiply dramatically the moment you want to scale across several machines or need to orchestrate complex workflows</strong>. Tasks like:</p>
<ul>
<li>Launching jobs and synchronizing them across machines,</li>
<li>Managing different workers, node failures, and resuming or monitoring experiments,</li>
<li>Efficiently using both CPUs (for pre-processing and data loading) and GPUs (for training/inference) in one seamless workflow,</li>
<li>Sharding and streaming large datasets not just for one epoch, but for repeated, distributed, and fault-tolerant training, becomes <strong>painful and complex</strong> with only PyTorch’s stock tools.</li>
</ul>
<p>This is exactly where <strong>Ray</strong> shines.</p>
<p>It abstracts away the low-level engineering required to run distributed workloads at scale. For instance, with <strong>Ray Train</strong> and <strong>Ray Data</strong>, you get seamless multi-GPU, multi-node orchestration, unified CPU-GPU pipelines, resilience and scalability. This helps you focus on your algorithms and models, rather than the underlying infrastructure.</p>
</div>
</div>
</section>
</section>
<section id="distributed-training-with-ray-train-and-pytorch" class="level1">
<h1>Distributed Training with Ray Train and PyTorch</h1>
<p>Now that we have understood the basics of Ray and how it can help us scale any application, let’s now dive deep into distributed training with Ray Train and PyTorch.</p>
<p align="center">
<img src="assets/ray_03.png" alt="Distributed Training with Ray Train and PyTorch" width="100%">
</p>
<p>Before diving into distributed training, let’s establish a baseline by looking at a simple single-GPU training loop. This will help us understand what needs to change when we migrate to distributed training.</p>
<section id="single-gpu-pytorch-training-on-cifar-10" class="level2">
<h2 class="anchored" data-anchor-id="single-gpu-pytorch-training-on-cifar-10">Single-GPU PyTorch Training on CIFAR-10</h2>
<p>We’ll use a <code>Vision Transformer</code> model (<code>torchvision.models.VisionTransformer</code>) and the <code>CIFAR-10</code> dataset. This code works on CPU, GPU (CUDA), or Apple MPS, but it’s strictly ordinary, non-distributed PyTorch.</p>
<p>If you have trained any model with <strong>PyTorch</strong> on a single machine/colab notebook, you might have seen a similar training loop, where we:</p>
<ol type="1">
<li>Download and prepare the <code>dataset</code>
<ul>
<li>Set up <code>data loaders</code></li>
</ul></li>
<li>Define the <code>model</code>
<ul>
<li>Move the model to the available device (GPU, MPS, or CPU).</li>
</ul></li>
<li>Set up <code>optimizer</code> and <code>loss</code>.</li>
<li>Run the <code>training loop</code>.
<ul>
<li>Iterate over training data to update model weights.</li>
<li>Check accuracy on validation data.</li>
</ul></li>
<li>Optionally, <code>checkpoint</code> the model at the end.</li>
</ol>
<p>This works perfectly for <em>one GPU or a single machine</em>, but doesn’t scale automatically. We’ll see soon how to migrate this to Ray Train for scaling, but for now, here’s the basic setup.</p>
<section id="dataloader-function" class="level3">
<h3 class="anchored" data-anchor-id="dataloader-function">DataLoader Function</h3>
<p>This function sets up the <a href="https://pytorch.org/docs/stable/data.html">DataLoaders</a> for the CIFAR-10 training and test splits.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-10-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-1" role="tab" aria-controls="tabset-10-1" aria-selected="true" href="">Define the DataLoader Function</a></li></ul>
<div class="tab-content">
<div id="tabset-10-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-10-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> Normalize, ToTensor</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> filelock <span class="im">import</span> FileLock</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_dataloaders(batch_size):</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Create standard PyTorch DataLoaders.</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">    No distributed code, just vanilla PyTorch.</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>        ToTensor(),</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>        Normalize((<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), (<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>))</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> FileLock(os.path.expanduser(<span class="st">"~/data.lock"</span>)):</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>        train_data <span class="op">=</span> datasets.CIFAR10(</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>            root<span class="op">=</span><span class="st">"~/data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform,</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>        test_data <span class="op">=</span> datasets.CIFAR10(</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>            root<span class="op">=</span><span class="st">"~/data"</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform,</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> DataLoader(train_data, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>    test_loader <span class="op">=</span> DataLoader(test_data, batch_size<span class="op">=</span>batch_size)</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_loader, test_loader</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Why use a FileLock?">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Why use a FileLock?
</div>
</div>
<div class="callout-body-container callout-body">
<p>We use a <code>FileLock</code> to avoid concurrency issues if datasets are being downloaded.</p>
</div>
</div>
</section>
<section id="training-function" class="level3">
<h3 class="anchored" data-anchor-id="training-function">Training Function</h3>
<p>This is the standard PyTorch training loop, using <code>torchvision.models.VisionTransformer</code>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-11-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-1" role="tab" aria-controls="tabset-11-1" aria-selected="true" href="">Define the Training Function</a></li></ul>
<div class="tab-content">
<div id="tabset-11-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-11-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> VisionTransformer</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_func(lr<span class="op">=</span><span class="fl">1e-3</span>, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">512</span>):</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Main training function: single machine, single GPU.</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get data loaders</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    train_loader, val_loader <span class="op">=</span> get_dataloaders(batch_size<span class="op">=</span>batch_size)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the model</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> VisionTransformer(</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span><span class="dv">32</span>,   <span class="co"># CIFAR-10 images are 32x32</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>        patch_size<span class="op">=</span><span class="dv">4</span>,    <span class="co"># Reasonable patch size for CIFAR-10</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>        num_layers<span class="op">=</span><span class="dv">12</span>,   <span class="co"># Transformer layers</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">8</span>,     <span class="co"># Attention heads</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>        hidden_dim<span class="op">=</span><span class="dv">384</span>,  <span class="co"># Model width</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        mlp_dim<span class="op">=</span><span class="dv">768</span>,     <span class="co"># Transformer MLP dim</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span><span class="dv">10</span>   <span class="co"># CIFAR-10</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Move model to correct device (GPU/MPS/CPU)</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'mps'</span> <span class="cf">if</span> torch.backends.mps.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    model.to(device)</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set up loss and optimizer</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>lr, weight_decay<span class="op">=</span><span class="fl">1e-2</span>)</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training loop</span></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Training phase</span></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X, y <span class="kw">in</span> tqdm(train_loader, desc<span class="op">=</span><span class="ss">f"Train Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>):</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>            X, y <span class="op">=</span> X.to(device), y.to(device)</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> model(X)</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(pred, y)</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>            train_loss <span class="op">+=</span> loss.item()</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">/=</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Validation phase</span></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>        val_loss, num_correct, num_total <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> X, y <span class="kw">in</span> tqdm(val_loader, desc<span class="op">=</span><span class="ss">f"Valid Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>):</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a>                X, y <span class="op">=</span> X.to(device), y.to(device)</span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>                pred <span class="op">=</span> model(X)</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> loss_fn(pred, y)</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>                val_loss <span class="op">+=</span> loss.item()</span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a>                num_total <span class="op">+=</span> y.shape[<span class="dv">0</span>]</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a>                num_correct <span class="op">+=</span> (pred.argmax(<span class="dv">1</span>) <span class="op">==</span> y).<span class="bu">sum</span>().item()</span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>        val_loss <span class="op">/=</span> <span class="bu">len</span>(val_loader)</span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> num_correct <span class="op">/</span> num_total</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Train Loss: </span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss"> | Valid Loss: </span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss"> | Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span><span class="dv">100</span> <span class="op">*</span> accuracy<span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Optional: Save checkpoint</span></span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a>    checkpoint <span class="op">=</span> {</span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a>        <span class="st">'epoch'</span>: epochs,</span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a>        <span class="st">'model_state_dict'</span>: model.state_dict(),</span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a>        <span class="st">'optimizer_state_dict'</span>: optimizer.state_dict(),</span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a>        <span class="st">'accuracy'</span>: accuracy,</span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a>    torch.save(checkpoint, <span class="st">'checkpoint_single_machine.pth'</span>)</span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Training completed! Final accuracy: </span><span class="sc">{</span><span class="dv">100</span> <span class="op">*</span> accuracy<span class="sc">:.2f}</span><span class="ss">%</span><span class="ch">\n</span><span class="ss">Checkpoint saved to checkpoint_single_machine.pth"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</section>
<section id="training-the-model" class="level3">
<h3 class="anchored" data-anchor-id="training-the-model">Training the Model</h3>
<p>Let’s now train the model on a single GPU.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>train_func(lr<span class="op">=</span><span class="fl">1e-3</span>, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">512</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p align="center">
<img src="assets/gpu_01.png" alt="Training the Model" width="100%">
</p>
<p>As you can see, the model is trained on a single GPU while other GPUs are idle.</p>
<p>This script represents plain vanilla <strong>PyTorch</strong>, suitable for a single GPU or single CPU. There is no distributed logic or <strong>Ray</strong> involved yet. All of the key logic, especially the <code>get_dataloaders</code> function and the structure of the <code>train_func</code> will remain mostly the same when we migrate to distributed training with <strong>Ray Train</strong>.</p>
<p>Let’s now train the model at scale on multiple GPUs across multiple machines.</p>
</section>
</section>
<section id="distributed-training-with-ray-train" class="level2">
<h2 class="anchored" data-anchor-id="distributed-training-with-ray-train">Distributed Training with Ray Train</h2>
<p>Now, let’s see how to migrate this <code>single-machine</code>, <code>single-GPU</code> training loop to <code>distributed training</code> using <strong>Ray Train</strong> and <strong>PyTorch</strong> on <code>multiple machines</code>, <code>multiple GPUs</code>.</p>
<p align="center">
<video controls="" width="700">
<source src="assets/ray_train_01.mov" type="video/mp4">
Your browser does not support the video tag. </video> <br> <em>Distributed Training with Ray Train Key Concepts.</em>
</p>
<section id="ray-train-architecture" class="level3">
<h3 class="anchored" data-anchor-id="ray-train-architecture">Ray Train Architecture</h3>
<p><strong>Ray Train’s</strong> architecture is based on the following components:</p>
<ol type="1">
<li>A Ray Train <code>Controller/Driver</code> that schedules the training workers, handles errors, and manages checkpoints<br>
</li>
<li>Ray Train <code>Workers</code> that execute the training code</li>
</ol>
<p align="center">
<img src="assets/ray_train__01.png" width="700">
</p>
<p>Below are the key API concepts of <strong>Ray Train</strong>:</p>
<ol type="1">
<li><code>train_loop_per_worker</code>: The core function that contains your model training logic<br>
</li>
<li><code>ScalingConfig</code>: Specifies the number of workers and compute resources (CPUs, GPUs, TPUs)<br>
</li>
<li><code>Trainer</code>: Manages the training process<br>
</li>
<li><code>Trainer.fit()</code>: Starts the distributed training job</li>
</ol>
<p align="center">
<img src="assets/ray_train_02.png" width="700" loading="lazy">
</p>
</section>
<section id="ray-data-and-ray-train-integration" class="level3">
<h3 class="anchored" data-anchor-id="ray-data-and-ray-train-integration">Ray Data and Ray Train Integration</h3>
<p>Here is a diagram showing the <strong>Ray Data</strong> and <strong>Ray Train</strong> integration.</p>
<p align="center">
<img src="assets/ray_train_03.png" width="800" loading="lazy">
</p>
<p>We are not going to go into the details of Ray Data and Ray Train integration in this blog post. But if you are interested in learning more about it, you can check out the <a href="https://docs.ray.io/en/latest/train/user-guides/data-loading-preprocessing.html">Ray Data</a> documentation.</p>
</section>
</section>
<section id="setup-the-environment" class="level2">
<h2 class="anchored" data-anchor-id="setup-the-environment">Setup the Environment</h2>
<p>Before we start any training, let’s first check how many GPUs (and CPUs) are available in our <strong>Ray Cluster</strong>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-12-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-12-1" role="tab" aria-controls="tabset-12-1" aria-selected="true" href="">Check Cluster GPUs</a></li></ul>
<div class="tab-content">
<div id="tabset-12-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-12-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ray</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_cluster_gpus():</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Check GPU count in the entire Ray cluster."""</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize Ray if not already initialized</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ray.is_initialized():</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>        ray.init()</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get cluster resources (total GPUs in cluster)</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    cluster_resources <span class="op">=</span> ray.cluster_resources()</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    total_gpus <span class="op">=</span> cluster_resources.get(<span class="st">"GPU"</span>, <span class="dv">0</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get available resources (currently available GPUs)</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    available_resources <span class="op">=</span> ray.available_resources()</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    available_gpus <span class="op">=</span> available_resources.get(<span class="st">"GPU"</span>, <span class="dv">0</span>)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get local GPU count (GPUs on this node only)</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    local_gpus <span class="op">=</span> torch.cuda.device_count() <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print results</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Ray Cluster GPU Information"</span>)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total GPUs in cluster:     </span><span class="sc">{</span><span class="bu">int</span>(total_gpus)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Available GPUs in cluster: </span><span class="sc">{</span><span class="bu">int</span>(available_gpus)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Local GPUs (head node):    </span><span class="sc">{</span>local_gpus<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Additional cluster info</span></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Cluster Resources:"</span>)</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  CPUs (total):     </span><span class="sc">{</span><span class="bu">int</span>(cluster_resources.get(<span class="st">'CPU'</span>, <span class="dv">0</span>))<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  CPUs (available): </span><span class="sc">{</span><span class="bu">int</span>(available_resources.get(<span class="st">'CPU'</span>, <span class="dv">0</span>))<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show node details if available</span></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>        nodes <span class="op">=</span> ray.nodes()</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Cluster Nodes: </span><span class="sc">{</span><span class="bu">len</span>(nodes)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, node <span class="kw">in</span> <span class="bu">enumerate</span>(nodes):</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>            node_resources <span class="op">=</span> node.get(<span class="st">'Resources'</span>, {})</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>            node_gpus <span class="op">=</span> node_resources.get(<span class="st">'GPU'</span>, <span class="dv">0</span>)</span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  Node </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="bu">int</span>(node_gpus)<span class="sc">}</span><span class="ss"> GPU(s)"</span>)</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Note: Could not retrieve node details: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">'total_gpus'</span>: <span class="bu">int</span>(total_gpus),</span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">'available_gpus'</span>: <span class="bu">int</span>(available_gpus),</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">'local_gpus'</span>: local_gpus</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a>    check_cluster_gpus()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p>As you can see, the cluster which I have has a total of 8 GPUs. The cluster consists of a total of one Head Node and two Worker Nodes, with each worker node having 4 GPUs.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb22"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="ex">============================================================</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Ray</span> Cluster GPU Information</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="ex">============================================================</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="ex">Total</span> GPUs in cluster:     8</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="ex">Available</span> GPUs in cluster: 8</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="ex">Local</span> GPUs <span class="er">(</span><span class="fu">head</span> node<span class="kw">)</span><span class="bu">:</span>    0</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="ex">============================================================</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="ex">Cluster</span> Resources:</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>  <span class="ex">CPUs</span> <span class="er">(</span><span class="ex">total</span><span class="kw">)</span><span class="bu">:</span>     96</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>  <span class="ex">CPUs</span> <span class="er">(</span><span class="ex">available</span><span class="kw">)</span><span class="bu">:</span> 96</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="ex">Cluster</span> Nodes: 3</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>  <span class="ex">Node</span> 1: 0 GPU<span class="er">(</span><span class="ex">s</span><span class="kw">)</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>  <span class="ex">Node</span> 2: 4 GPU<span class="er">(</span><span class="ex">s</span><span class="kw">)</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>  <span class="ex">Node</span> 3: 4 GPU<span class="er">(</span><span class="ex">s</span><span class="kw">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="distributed-training-with-ray-train-and-pytorch-fsdp" class="level2">
<h2 class="anchored" data-anchor-id="distributed-training-with-ray-train-and-pytorch-fsdp">Distributed Training with Ray Train and PyTorch FSDP</h2>
<p>Now that we have understood the basics of Ray Train, and also have a Ray cluster ready, let’s now dive into distributed training with Ray Train and PyTorch FSDP.</p>
<section id="specify-cluster-scaling" class="level3">
<h3 class="anchored" data-anchor-id="specify-cluster-scaling">1. Specify Cluster Scaling</h3>
<p>First, set up how many Ray workers (processes) will participate, typically one per GPU. For a Ray cluster with 8 GPUs:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-13-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-13-1" role="tab" aria-controls="tabset-13-1" aria-selected="true" href="">Specify Cluster Scaling</a></li></ul>
<div class="tab-content">
<div id="tabset-13-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-13-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>scaling_config <span class="op">=</span> ScalingConfig(</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">8</span>,  <span class="co"># e.g., 8 GPUs in our cluster</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    use_gpu<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    resources_per_worker<span class="op">=</span>{<span class="st">"CPU"</span>: <span class="dv">2</span>, <span class="st">"GPU"</span>: <span class="dv">1</span>},</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</section>
<section id="data-preparation-pytorch-dataloaders" class="level3">
<h3 class="anchored" data-anchor-id="data-preparation-pytorch-dataloaders">2. Data Preparation: PyTorch DataLoaders</h3>
<p>Data preparation is unchanged from typical PyTorch or DDP usage. Use our usual transforms and DataLoader logic:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-14-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-14-1" role="tab" aria-controls="tabset-14-1" aria-selected="true" href="">Define the DataLoaders</a></li></ul>
<div class="tab-content">
<div id="tabset-14-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-14-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> filelock <span class="im">import</span> FileLock</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_dataloaders(batch_size):</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize((<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), (<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>)),</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> FileLock(os.path.expanduser(<span class="st">"~/data.lock"</span>)):</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        train_ds <span class="op">=</span> datasets.CIFAR10(<span class="st">"~/data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        valid_ds <span class="op">=</span> datasets.CIFAR10(<span class="st">"~/data"</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        DataLoader(train_ds, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>        DataLoader(valid_ds, batch_size<span class="op">=</span>batch_size),</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p>No special considerations are needed for FSDP at this stage.</p>
</section>
<section id="define-the-training-function-1" class="level3">
<h3 class="anchored" data-anchor-id="define-the-training-function-1">3. Define the Training Function</h3>
<p>Next, let’s define the training function for the Ray Train worker. This is the training function that will be executed by each worker.</p>
<p>As the model is now being prepared for FSDP, we need to use the <code>prepare_model</code> function to prepare the model for FSDP.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-15-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-15-1" role="tab" aria-controls="tabset-15-1" aria-selected="true" href="">Define the Training Function</a></li></ul>
<div class="tab-content">
<div id="tabset-15-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-15-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_func_per_worker(config):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    lr <span class="op">=</span> config[<span class="st">"lr"</span>]</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    epochs <span class="op">=</span> config[<span class="st">"epochs"</span>]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> config[<span class="st">"batch_size_per_worker"</span>]</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    ctx <span class="op">=</span> ray.train.get_context()</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    rank <span class="op">=</span> ctx.get_world_rank()</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    world_size <span class="op">=</span> ctx.get_world_size()</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> rank <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Training with FSDP across </span><span class="sc">{</span>world_size<span class="sc">}</span><span class="ss"> workers..."</span>)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prepare DataLoaders for distributed training</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    train_dl, valid_dl <span class="op">=</span> get_dataloaders(batch_size)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    train_dl <span class="op">=</span> ray.train.torch.prepare_data_loader(train_dl)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>    valid_dl <span class="op">=</span> ray.train.torch.prepare_data_loader(valid_dl)</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the model</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> VisionTransformer(</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span><span class="dv">32</span>, patch_size<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>        num_layers<span class="op">=</span><span class="dv">12</span>, num_heads<span class="op">=</span><span class="dv">8</span>, hidden_dim<span class="op">=</span><span class="dv">384</span>, mlp_dim<span class="op">=</span><span class="dv">768</span>, num_classes<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prepare the model for FSDP</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> ray.train.torch.prepare_model(model, parallel_strategy<span class="op">=</span><span class="st">"fsdp"</span>)</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>lr, weight_decay<span class="op">=</span><span class="fl">1e-2</span>)</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>        total_loss, sample_cnt <span class="op">=</span> <span class="fl">0.0</span>, <span class="dv">0</span></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X, y <span class="kw">in</span> train_dl:</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> model(X)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(pred, y)</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item() <span class="op">*</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>            sample_cnt <span class="op">+=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">=</span> total_loss <span class="op">/</span> sample_cnt</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Validation loop</span></span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>        valid_loss, correct, total <span class="op">=</span> <span class="fl">0.0</span>, <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> X, y <span class="kw">in</span> valid_dl:</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>                pred <span class="op">=</span> model(X)</span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>                valid_loss <span class="op">+=</span> criterion(pred, y).item() <span class="op">*</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>                total <span class="op">+=</span> y.shape[<span class="dv">0</span>]</span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>                correct <span class="op">+=</span> (pred.argmax(dim<span class="op">=</span><span class="dv">1</span>) <span class="op">==</span> y).<span class="bu">sum</span>().item()</span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a>        valid_loss <span class="op">/=</span> total</span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> correct <span class="op">/</span> total</span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> rank <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: Train Loss=</span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss"> Valid Loss=</span><span class="sc">{</span>valid_loss<span class="sc">:.4f}</span><span class="ss"> Acc=</span><span class="sc">{</span>acc<span class="sc">:.3%}</span><span class="ss">"</span>)</span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>        metrics <span class="op">=</span> {<span class="st">"epoch"</span>: epoch<span class="op">+</span><span class="dv">1</span>, <span class="st">"train_loss"</span>: train_loss, <span class="st">"valid_loss"</span>: valid_loss, <span class="st">"accuracy"</span>: acc}</span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Checkpoint every 5 epochs</span></span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> tempfile.TemporaryDirectory() <span class="im">as</span> ckpt_dir:</span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a>                torch.save(model.module.state_dict(), os.path.join(ckpt_dir, <span class="st">"model.pt"</span>))</span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a>                ray.train.report(metrics, checkpoint<span class="op">=</span>ray.train.Checkpoint.from_directory(ckpt_dir))</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>            ray.train.report(metrics)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Change the parallel strategy to DDP">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Change the parallel strategy to DDP
</div>
</div>
<div class="callout-body-container callout-body">
<p>To change the parallel strategy to DDP, simply change the parameter to <code>"ddp"</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ray.train.torch.prepare_model(model, parallel_strategy<span class="op">=</span><span class="st">"fsdp"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="configure-run-checkpointing-and-storage" class="level3">
<h3 class="anchored" data-anchor-id="configure-run-checkpointing-and-storage">4. Configure Run Checkpointing and Storage</h3>
<p>We now use <strong>Ray’s</strong> checkpointing utilities to save the best results and recoverable states:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-16-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-16-1" role="tab" aria-controls="tabset-16-1" aria-selected="true" href="">Configure Run Checkpointing and Storage</a></li></ul>
<div class="tab-content">
<div id="tabset-16-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-16-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.train <span class="im">import</span> RunConfig, CheckpointConfig</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>checkpoint_config <span class="op">=</span> CheckpointConfig(</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    num_to_keep<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    checkpoint_score_attribute<span class="op">=</span><span class="st">"accuracy"</span>,</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    checkpoint_score_order<span class="op">=</span><span class="st">"max"</span>,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>run_config <span class="op">=</span> RunConfig(</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    name<span class="op">=</span><span class="st">"cifar10_fsdp_example"</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    storage_path<span class="op">=</span><span class="st">"/mnt/cluster_storage/training/"</span>,  <span class="co"># Use a persistent/shared location</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    checkpoint_config<span class="op">=</span>checkpoint_config,</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</section>
<section id="launch-training-with-torchtrainer" class="level3">
<h3 class="anchored" data-anchor-id="launch-training-with-torchtrainer">5. Launch Training with TorchTrainer</h3>
<p>Bring all the configs together and kick off distributed training:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-17-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-17-1" role="tab" aria-controls="tabset-17-1" aria-selected="true" href="">Launch Training with TorchTrainer</a></li></ul>
<div class="tab-content">
<div id="tabset-17-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-17-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.train.torch <span class="im">import</span> TorchTrainer</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>global_batch_size <span class="op">=</span> <span class="dv">1024</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>num_workers <span class="op">=</span> <span class="dv">8</span>   </span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>batch_size_per_worker <span class="op">=</span> global_batch_size <span class="op">//</span> num_workers</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>train_loop_config <span class="op">=</span> {</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"lr"</span>: <span class="fl">1e-3</span>,</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"epochs"</span>: <span class="dv">20</span>,</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"batch_size_per_worker"</span>: batch_size_per_worker,</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> TorchTrainer(</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    train_loop_per_worker<span class="op">=</span>train_func_per_worker,</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>    train_loop_config<span class="op">=</span>train_loop_config,</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    scaling_config<span class="op">=</span>scaling_config,</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    run_config<span class="op">=</span>run_config,</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Starting FSDP distributed training..."</span>)</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> trainer.fit()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</section>
<section id="load-and-use-checkpoints" class="level3">
<h3 class="anchored" data-anchor-id="load-and-use-checkpoints">6. Load and Use Checkpoints</h3>
<p>Once the training is complete, the model can be restored from the best checkpoint:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-18-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-18-1" role="tab" aria-controls="tabset-18-1" aria-selected="true" href="">Load and Use Checkpoints</a></li></ul>
<div class="tab-content">
<div id="tabset-18-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-18-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> VisionTransformer</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>ckpt <span class="op">=</span> result.checkpoint</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> ckpt.as_directory() <span class="im">as</span> ckpt_dir:</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    model_path <span class="op">=</span> os.path.join(ckpt_dir, <span class="st">"model.pt"</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> VisionTransformer(</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span><span class="dv">32</span>, patch_size<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>        num_layers<span class="op">=</span><span class="dv">12</span>, num_heads<span class="op">=</span><span class="dv">8</span>, hidden_dim<span class="op">=</span><span class="dv">384</span>, mlp_dim<span class="op">=</span><span class="dv">768</span>, num_classes<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    state_dict <span class="op">=</span> torch.load(model_path, map_location<span class="op">=</span><span class="st">"cpu"</span>)</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(state_dict)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p>Let’s now put all the pieces together and train the model on the cluster.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-19-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-19-1" role="tab" aria-controls="tabset-19-1" aria-selected="true" href="">train_fsdp.py</a></li></ul>
<div class="tab-content">
<div id="tabset-19-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-19-1-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tempfile</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> VisionTransformer</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> filelock <span class="im">import</span> FileLock</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ray</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.train <span class="im">import</span> ScalingConfig, RunConfig, CheckpointConfig</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.train.torch <span class="im">import</span> TorchTrainer</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_dataloaders(batch_size):</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize((<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), (<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>))</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> FileLock(os.path.expanduser(<span class="st">"~/data.lock"</span>)):</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>        train_data <span class="op">=</span> datasets.CIFAR10(root<span class="op">=</span><span class="st">"~/data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>        valid_data <span class="op">=</span> datasets.CIFAR10(root<span class="op">=</span><span class="st">"~/data"</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> DataLoader(train_data, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    valid_loader <span class="op">=</span> DataLoader(valid_data, batch_size<span class="op">=</span>batch_size)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_loader, valid_loader</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_func_per_worker(config):</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    lr <span class="op">=</span> config[<span class="st">"lr"</span>]</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>    epochs <span class="op">=</span> config[<span class="st">"epochs"</span>]</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> config[<span class="st">"batch_size_per_worker"</span>]</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>    ctx <span class="op">=</span> ray.train.get_context()</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>    world_size <span class="op">=</span> ctx.get_world_size()</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>    local_rank <span class="op">=</span> ctx.get_world_rank()</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_rank <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"FSDP Training on </span><span class="sc">{</span>world_size<span class="sc">}</span><span class="ss"> workers"</span>)</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>    train_loader, valid_loader <span class="op">=</span> get_dataloaders(batch_size)</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> ray.train.torch.prepare_data_loader(train_loader)</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>    valid_loader <span class="op">=</span> ray.train.torch.prepare_data_loader(valid_loader)</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> VisionTransformer(</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span><span class="dv">32</span>, patch_size<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>        num_layers<span class="op">=</span><span class="dv">12</span>, num_heads<span class="op">=</span><span class="dv">8</span>, hidden_dim<span class="op">=</span><span class="dv">384</span>, mlp_dim<span class="op">=</span><span class="dv">768</span>, num_classes<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># [FSDP] Key change from DDP:</span></span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> ray.train.torch.prepare_model(model, parallel_strategy<span class="op">=</span><span class="st">"fsdp"</span>)</span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>lr, weight_decay<span class="op">=</span><span class="fl">1e-2</span>)</span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a>        train_loss, n <span class="op">=</span> <span class="fl">0.0</span>, <span class="dv">0</span></span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X, y <span class="kw">in</span> train_loader:</span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> model(X)</span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(pred, y)</span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a>            train_loss <span class="op">+=</span> loss.item() <span class="op">*</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a>            n <span class="op">+=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">/=</span> n</span>
<span id="cb30-62"><a href="#cb30-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-63"><a href="#cb30-63" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb30-64"><a href="#cb30-64" aria-hidden="true" tabindex="-1"></a>        correct, total, valid_loss <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.0</span></span>
<span id="cb30-65"><a href="#cb30-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb30-66"><a href="#cb30-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> X, y <span class="kw">in</span> valid_loader:</span>
<span id="cb30-67"><a href="#cb30-67" aria-hidden="true" tabindex="-1"></a>                pred <span class="op">=</span> model(X)</span>
<span id="cb30-68"><a href="#cb30-68" aria-hidden="true" tabindex="-1"></a>                valid_loss <span class="op">+=</span> criterion(pred, y).item() <span class="op">*</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb30-69"><a href="#cb30-69" aria-hidden="true" tabindex="-1"></a>                total <span class="op">+=</span> y.shape[<span class="dv">0</span>]</span>
<span id="cb30-70"><a href="#cb30-70" aria-hidden="true" tabindex="-1"></a>                correct <span class="op">+=</span> (pred.argmax(dim<span class="op">=</span><span class="dv">1</span>) <span class="op">==</span> y).<span class="bu">sum</span>().item()</span>
<span id="cb30-71"><a href="#cb30-71" aria-hidden="true" tabindex="-1"></a>        valid_loss <span class="op">/=</span> total</span>
<span id="cb30-72"><a href="#cb30-72" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> correct <span class="op">/</span> total</span>
<span id="cb30-73"><a href="#cb30-73" aria-hidden="true" tabindex="-1"></a>        metrics <span class="op">=</span> {</span>
<span id="cb30-74"><a href="#cb30-74" aria-hidden="true" tabindex="-1"></a>            <span class="st">"epoch"</span>: epoch <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb30-75"><a href="#cb30-75" aria-hidden="true" tabindex="-1"></a>            <span class="st">"train_loss"</span>: train_loss,</span>
<span id="cb30-76"><a href="#cb30-76" aria-hidden="true" tabindex="-1"></a>            <span class="st">"valid_loss"</span>: valid_loss,</span>
<span id="cb30-77"><a href="#cb30-77" aria-hidden="true" tabindex="-1"></a>            <span class="st">"accuracy"</span>: accuracy</span>
<span id="cb30-78"><a href="#cb30-78" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb30-79"><a href="#cb30-79" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save a checkpoint every 5 epochs</span></span>
<span id="cb30-80"><a href="#cb30-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb30-81"><a href="#cb30-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> tempfile.TemporaryDirectory() <span class="im">as</span> tmp_ckpt_dir:</span>
<span id="cb30-82"><a href="#cb30-82" aria-hidden="true" tabindex="-1"></a>                torch.save(model.module.state_dict(),</span>
<span id="cb30-83"><a href="#cb30-83" aria-hidden="true" tabindex="-1"></a>                           os.path.join(tmp_ckpt_dir, <span class="st">"model.pt"</span>))</span>
<span id="cb30-84"><a href="#cb30-84" aria-hidden="true" tabindex="-1"></a>                ray.train.report(metrics, checkpoint<span class="op">=</span>ray.train.Checkpoint.from_directory(tmp_ckpt_dir))</span>
<span id="cb30-85"><a href="#cb30-85" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb30-86"><a href="#cb30-86" aria-hidden="true" tabindex="-1"></a>            ray.train.report(metrics)</span>
<span id="cb30-87"><a href="#cb30-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-88"><a href="#cb30-88" aria-hidden="true" tabindex="-1"></a>scaling_config <span class="op">=</span> ScalingConfig(num_workers<span class="op">=</span><span class="dv">8</span>, use_gpu<span class="op">=</span><span class="va">True</span>, resources_per_worker<span class="op">=</span>{<span class="st">"CPU"</span>: <span class="dv">2</span>, <span class="st">"GPU"</span>: <span class="dv">1</span>})</span>
<span id="cb30-89"><a href="#cb30-89" aria-hidden="true" tabindex="-1"></a>checkpoint_config <span class="op">=</span> CheckpointConfig(num_to_keep<span class="op">=</span><span class="dv">2</span>, checkpoint_score_attribute<span class="op">=</span><span class="st">"accuracy"</span>, checkpoint_score_order<span class="op">=</span><span class="st">"max"</span>)</span>
<span id="cb30-90"><a href="#cb30-90" aria-hidden="true" tabindex="-1"></a>run_config <span class="op">=</span> RunConfig(name<span class="op">=</span><span class="st">"cifar10_fsdp_example"</span>, storage_path<span class="op">=</span><span class="st">"/mnt/cluster_storage/training/"</span>, checkpoint_config<span class="op">=</span>checkpoint_config)</span>
<span id="cb30-91"><a href="#cb30-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-92"><a href="#cb30-92" aria-hidden="true" tabindex="-1"></a>global_batch_size <span class="op">=</span> <span class="dv">1024</span></span>
<span id="cb30-93"><a href="#cb30-93" aria-hidden="true" tabindex="-1"></a>batch_size_per_worker <span class="op">=</span> global_batch_size <span class="op">//</span> scaling_config.num_workers</span>
<span id="cb30-94"><a href="#cb30-94" aria-hidden="true" tabindex="-1"></a>train_loop_config <span class="op">=</span> {<span class="st">"lr"</span>: <span class="fl">1e-3</span>, <span class="st">"epochs"</span>: <span class="dv">20</span>, <span class="st">"batch_size_per_worker"</span>: batch_size_per_worker}</span>
<span id="cb30-95"><a href="#cb30-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-96"><a href="#cb30-96" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> TorchTrainer(</span>
<span id="cb30-97"><a href="#cb30-97" aria-hidden="true" tabindex="-1"></a>    train_loop_per_worker<span class="op">=</span>train_func_per_worker,</span>
<span id="cb30-98"><a href="#cb30-98" aria-hidden="true" tabindex="-1"></a>    train_loop_config<span class="op">=</span>train_loop_config,</span>
<span id="cb30-99"><a href="#cb30-99" aria-hidden="true" tabindex="-1"></a>    scaling_config<span class="op">=</span>scaling_config,</span>
<span id="cb30-100"><a href="#cb30-100" aria-hidden="true" tabindex="-1"></a>    run_config<span class="op">=</span>run_config,</span>
<span id="cb30-101"><a href="#cb30-101" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb30-102"><a href="#cb30-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-103"><a href="#cb30-103" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> trainer.fit()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p>While the training is runing, we can see the progress in the Ray dashboard. We can now see that all 8 GPUs are being used for training.</p>
<p align="center">
<img src="assets/gpu_02.png" alt="Ray Train FSDP Dashboard" width="100%">
</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Distributed training from scratch is often perceived as a complex and challenging endeavor, especially when it comes to configuring multiple GPUs and orchestrating communication between workers. However, modern open-source frameworks such as <strong>Ray Train</strong>, together with robust PyTorch features like <strong>FSDP</strong>, have significantly lowered the barrier to scalable, efficient distributed deep learning. In this blog, we walked through a step-by-step workflow for setting up a distributed training pipeline to fine-tune a model on multiple GPUs, leveraging Ray Train for orchestration and PyTorch FSDP for efficient memory and communication management.</p>
<p>By utilizing <strong>Ray’s</strong> high-level abstractions, we are able to streamline the engineering process, eliminate much of the boilerplate involved in custom distributed training, and gain access to valuable capabilities such as experiment tracking, fault tolerance, and automatic checkpointing. <strong>Ray’s</strong> scaling configurations allow us to harness all available compute resources, whether just a few or dozens of GPUs, while its dashboard provides clear visibility into resource utilization and training progress in real-time.</p>
<p>In this blog, we mostly talk about <code>Data Parallelism (DP)</code> technique for scaling training to multiple GPUs. But for tackling even more demanding tasks with extremely large models and datasets, there are additional and more advanced techniques available. Strategies such as <code>Pipeline Parallelism</code>, <code>Tensor Parallelism</code>, and <code>Sequence Parallelism</code> have become key components in scaling deep learning to the frontier level. These methods allow models to be split across layers, parameters, or computation steps, enabling efficient training across clusters of GPUs.</p>
<p>Emerging practices in hybrid sharding, mixed precision, model offloading, and asynchronous optimization further push the boundaries of what is possible, empowering researchers and engineers to experiment at ever-increasing scales while managing resource and memory efficiency. Maybe in some future blog, we will discuss these advanced techniques in more detail (as I learn them :)).</p>
</section>
<section id="references-further-resources" class="level2">
<h2 class="anchored" data-anchor-id="references-further-resources">References &amp; Further Resources</h2>
<ul>
<li>Anyscale and Ray
<ul>
<li><a href="https://console.anyscale.com/register/v2">Getting Started with Ray on Anyscale</a></li>
</ul></li>
<li>Distributed Training
<ul>
<li><a href="https://lcs2.in/llm2501">Advanced Large Language Models [IIT Delhi]</a></li>
<li><a href="https://hanlab.mit.edu/courses/2024-fall-65940">TinyML and Efficient Deep Learning Computing [MIT]</a></li>
<li><a href="https://huggingface.co/spaces/nanotron/ultrascale-playbook?section=high-level_overview">Training LLMs on GPU Clusters</a></li>
<li><a href="https://www.youtube.com/watch?v=9MvD-XsowsE&amp;t=1068s">CS231N Lecture 11, Large Scale Distributed Training</a></li>
</ul></li>
<li>LLM and Advance Deep Learning
<ul>
<li><a href="https://theschoolof.ai/">The School of AI</a></li>
<li><a href="https://udlbook.github.io/udlbook/">Understanding Deep Learning</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLPTV0NXA_ZSgsLAr8YCgCwhPIJNNtexWu">Building LLMs from scratch</a></li>
</ul></li>
<li>Ray and PyTorch
<ul>
<li><a href="https://docs.ray.io/en/latest/train/train.html">Ray Train Documentation</a></li>
<li><a href="https://docs.pytorch.org/docs/stable/distributed.fsdp.fully_shard.html">PyTorch FSDP2 Documentation</a></li>
<li><a href="https://docs.ray.io/en/latest/train/user-guides/data-loading-preprocessing.html">Ray Data Documentation</a></li>
</ul></li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/debnsuma\.github\.io\/my-blog");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>