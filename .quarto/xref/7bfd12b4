{"entries":[],"headings":["introduction","deep-learning-training-basics","bottlenecks-in-single-gpu-training","static-memory","dynamic-memory","batch-size-intuition","memory-usage-in-transformer","solution-1-activation-recomputation","solution-2-gradient-accumulation","scaling-with-multiple-gpus-data-parallelism-dp","the-data-parallel-setup","gradient-synchronization-the-all-reduce-primitive","overlapping-communication-and-computation","the-limitations-of-simple-data-parallelism-dp","zero-zero-redundancy-optimizer","zero-1-sharding-optimizer-states","zero-2-sharding-gradients","zero-3-sharding-parameters"]}